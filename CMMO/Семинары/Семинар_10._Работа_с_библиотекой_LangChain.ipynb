{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Модуль 5. Работа с современными языковыми моделями\n","## Семинар №10. Работа с библиотекой LangChain\n","### Цель занятия: научиться работать с библиотекой LangChain по применению языковых моделей"],"metadata":{"id":"VBBsfZljDVtl"}},{"cell_type":"markdown","source":["LangChain — это платформа для разработки приложений на основе языковых моделей. LangChain упрощает сложные этапы работы и создания моделей искусственного интеллекта двумя способами:\n","1. <b>Интеграция.</b> Перенесите внешние данные (файлы, другие приложения и данные API) в свои LLM.\n","2. <b>Агентство.</b> Позвольте вашим LLM взаимодействовать со своей средой посредством принятия решений. Используйте LLM, чтобы решить, какое действие предпринять дальше."],"metadata":{"id":"tbsbbPhzDb4H"}},{"cell_type":"markdown","source":["## Почему LangChain\n","\n"],"metadata":{"id":"G8_CGrMUV_9f"}},{"cell_type":"markdown","source":["* **Компоненты** — LangChain позволяет легко заменять абстракции и компоненты, необходимые для работы с языковыми моделями.\n","* **Настраиваемые цепочки** — LangChain предоставляет готовую поддержку для использования и настройки цепочек — серии связанных вместе действий.\n","* **Скорость** — эта команда работает безумно быстро. Вы будете в курсе последних возможностей LLM.\n","* **Сообщество** — замечательные разногласия и поддержка сообщества, встречи, хакатоны и т. д.\n","\n","Хотя LLM могут быть простыми (ввод и вывод текста), можно быстро столкнуться с трудностями. При разработке более сложных приложений поможет LangChain.\n","\n","> **Примечание.** Этот семинар не охватывает все аспекты LangChain. Он составлен таким образом, чтобы вы могли как можно быстрее начать работу и добиться результатов. Для получения дополнительной информации ознакомьтесь с [концептуальной документацией LangChain](https://docs.langchain.com/docs/).\n","\n","Чтобы следовать этому руководству, вам понадобится ключ API OpenAI. Вы можете использовать его как переменную среды в файле .env, где находится этот блокнот Jupyter, или вставить его ниже вместо YourAPIKey. Если у вас есть вопросы, поместите эти инструкции в ChatGPT."],"metadata":{"id":"VYF_2qQoWTWd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dyEO8Y0guW5j"},"outputs":[],"source":["fireworks_api_key = 'h6ErCvhXbQ6lbtSb4ekjVJraLPBzbrJAVVgGXkjy17S2AXxT'"]},{"cell_type":"markdown","source":["## Компоненты LangChain"],"metadata":{"id":"cWHTNckpXRus"}},{"cell_type":"markdown","source":["### Схема — основа работы с большими языковыми моделями (LLM)"],"metadata":{"id":"turGNTrKXbJR"}},{"cell_type":"markdown","source":["Способ взаимодействия с LLM на естественном языке:"],"metadata":{"id":"Nt0sG1h3XiGa"}},{"cell_type":"code","source":["# You'll be working with simple strings (that'll soon grow in complexity!)\n","my_text = \"What day comes after Friday?\"\n","my_text"],"metadata":{"id":"rqfZPi9vXlFn","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"8ae70359-7b86-4799-e559-9094a529e27e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'What day comes after Friday?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["#### Сообщения чата"],"metadata":{"id":"nBIgdud9Xn5R"}},{"cell_type":"markdown","source":["Как текст, но указан тип сообщения (Система, Человек, ИИ):\n","\n","* Система — полезный фоновый контекст, который подсказывает ИИ, что делать.\n","* Человек — сообщения, которые призваны представлять пользователя.\n","* ИИ — сообщения, показывающие, что ответил ИИ.\n","Дополнительную информацию см. в [документации OpenAI](https://platform.openai.com/docs/guides/chat/introduction)."],"metadata":{"id":"b5dlUtAhXurv"}},{"cell_type":"code","source":["!pip install langchain\n","!pip install fireworks-ai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LD1NWzgRVmLk","outputId":"32f249ef-cefe-4514-b519-547c000ebd45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain\n","  Downloading langchain-0.0.324-py3-none-any.whl (1.9 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.9 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.22)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n","Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langsmith<0.1.0,>=0.0.52 (from langchain)\n","  Downloading langsmith-0.0.52-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n","Successfully installed dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.324 langsmith-0.0.52 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n","Collecting fireworks-ai\n","  Downloading fireworks_ai-0.6.0-py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from fireworks-ai)\n","  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx-sse (from fireworks-ai)\n","  Downloading httpx_sse-0.3.1-py3-none-any.whl (7.7 kB)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from fireworks-ai) (1.10.13)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fireworks-ai) (9.4.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->fireworks-ai) (2023.7.22)\n","Collecting httpcore<0.19.0,>=0.18.0 (from httpx->fireworks-ai)\n","  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->fireworks-ai) (3.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->fireworks-ai) (1.3.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->fireworks-ai) (4.5.0)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.19.0,>=0.18.0->httpx->fireworks-ai) (3.7.1)\n","Collecting h11<0.15,>=0.13 (from httpcore<0.19.0,>=0.18.0->httpx->fireworks-ai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx->fireworks-ai) (1.1.3)\n","Installing collected packages: httpx-sse, h11, httpcore, httpx, fireworks-ai\n","Successfully installed fireworks-ai-0.6.0 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 httpx-sse-0.3.1\n"]}]},{"cell_type":"code","source":["from langchain.chat_models import ChatFireworks\n","from langchain.schema import HumanMessage, SystemMessage, AIMessage\n","\n","# This it the language model we'll use. We'll talk about what we're doing below in the next section\n","chat = ChatFireworks(temperature=.7, fireworks_api_key = fireworks_api_key)"],"metadata":{"id":"D8DDGn5dX66Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Теперь создадим несколько сообщений, имитирующих чат с ботом:"],"metadata":{"id":"P5Rx-a2uX9aR"}},{"cell_type":"code","source":["chat(\n","    [\n","        SystemMessage(content=\"You are a nice AI bot that helps a user figure out what to eat in one short sentence\"),\n","        HumanMessage(content=\"I like tomatoes, what should I eat?\")\n","    ]\n",")"],"metadata":{"id":"zVbvBfWiX9kw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"43657442-8054-4502-fb01-3cfbec7e8fad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='Try a delicious tomato and mozzarella salad!')"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Мы также можем передать дополнительную историю чата с ответами от ИИ."],"metadata":{"id":"brkr3d0eX-4f"}},{"cell_type":"code","source":["chat(\n","    [\n","        SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n","        HumanMessage(content=\"I like the beaches where should I go?\"),\n","        AIMessage(content=\"You should go to Nice, France\"),\n","        HumanMessage(content=\"What else should I do when I'm there?\")\n","    ]\n",")"],"metadata":{"id":"upPakdWkX_Bd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dd4ddaae-e540-481f-8a38-797cce50e22d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"Nice, France is known for its stunning beaches, but there are plenty of other things to do while you're there! Why not visit the Promenade des Anglais, a famous seaside promenade that offers beautiful views of the Mediterranean? Or explore the historic Old Town, with its narrow streets and picturesque squares? You could also visit the Chagall Museum to see works by the famous artist, or take a boat tour of the Bay of Angels. Whatever you choose, Nice is sure to be a beautiful and memorable destination!\")"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["Или исключить системное сообщение:"],"metadata":{"id":"te4oNcUCYF1N"}},{"cell_type":"code","source":["chat(\n","    [\n","        HumanMessage(content=\"What day comes after Thursday?\")\n","    ]\n",")"],"metadata":{"id":"jMKCOpEGYD5G","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a3443db-f84a-416e-e5c8-9a0cdd854b65"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"Hello! I'm glad you asked! The day that comes after Thursday is Friday. 😊 Is there anything else I can help you with?\")"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["#### Документы"],"metadata":{"id":"zJ1__z1DYKIQ"}},{"cell_type":"markdown","source":["Объект, содержащий фрагмент текста и метаданные (дополнительная информация об этом тексте)."],"metadata":{"id":"oyMZ5W0MYKVz"}},{"cell_type":"code","source":["from langchain.schema import Document"],"metadata":{"id":"Uoriarv0YKa1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n","         metadata={\n","             'my_document_id' : 234234,\n","             'my_document_source' : \"The LangChain Papers\",\n","             'my_document_create_time' : 1680013019\n","         })"],"metadata":{"id":"tR4NbhBgYRE9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"21afab50-344e-4074-8937-506489cb0ba6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Document(page_content=\"This is my document. It is full of text that I've gathered from other places\", metadata={'my_document_id': 234234, 'my_document_source': 'The LangChain Papers', 'my_document_create_time': 1680013019})"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Но включать метаданные необязательно."],"metadata":{"id":"OP9wqC-dYUjd"}},{"cell_type":"code","source":["Document(page_content=\"This is my document. It is full of text that I've gathered from other places\")"],"metadata":{"id":"BOOCiMulYWEI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"98896857-4441-4169-a2b8-e719ebb2019c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Document(page_content=\"This is my document. It is full of text that I've gathered from other places\")"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### Модели — интерфейс к «мозгу» ИИ"],"metadata":{"id":"WjloD3kuYWR1"}},{"cell_type":"markdown","source":["#### Языковая модель"],"metadata":{"id":"2hxE1ynlYWZY"}},{"cell_type":"markdown","source":["**Языковая модель** — это модель, которая вводит ➡️ выводит текст."],"metadata":{"id":"xAUDa2nzYp-M"}},{"cell_type":"code","source":["from langchain.llms.fireworks import Fireworks\n","\n","llm = Fireworks(model_name=\"accounts/fireworks/models/llama-v2-13b\", fireworks_api_key = fireworks_api_key)"],"metadata":{"id":"7CHQyEk8YWge"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm(\"What day comes after Friday?\")"],"metadata":{"id":"ZKuy1Du8Yx-1","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"7592e6ab-1407-49bf-9bb3-cde9241dde0f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\nAnswer: Saturday\\n\\nWhat day comes after Sunday?\\n\\nAnswer: Monday'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["#### Чат-модель"],"metadata":{"id":"PCrgovmMY1wn"}},{"cell_type":"markdown","source":["**Чат-модель** — модель, которая принимает серию сообщений и возвращает выходные данные сообщения."],"metadata":{"id":"rNg1V_5tY16d"}},{"cell_type":"code","source":["from langchain.chat_models import ChatFireworks\n","from langchain.schema import HumanMessage, SystemMessage, AIMessage\n","\n","# This it the language model we'll use. We'll talk about what we're doing below in the next section\n","chat = ChatFireworks(temperature=1., fireworks_api_key = fireworks_api_key)"],"metadata":{"id":"Ydtx0vBwY2DV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chat(\n","    [\n","        SystemMessage(content=\"You are an unhelpful AI bot that makes a joke at whatever the user says\"),\n","        HumanMessage(content=\"I would like to go to New York, how should I do this?\")\n","    ]\n",")"],"metadata":{"id":"3XE9r1V3Y-WY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"01f5d0ea-5324-42a8-f950-a001c001f617"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"Oh, great! Another eager traveler looking to explore the bustling streets of New York City! *chuckles* Just kidding, you're probably going to end up lost in Times Square with a hot dog in one hand and a pretzel in the other. But hey, at least you'll have a good time, right? 😜\\n\\nBut seriously, if you're looking to actually make it to New York, you're in luck! There are plenty of ways to get there. You could fly into one of the city's three major airports (JFK, LGA, or EWR), or take the train from nearby cities like Philadelphia or Boston. Or, if you're feeling adventurous, you could always walk there... but let's be real, that's not exactly the most practical option. 😅\\n\\nOnce you're in the city, there's no shortage of things to see and do. From iconic landmarks like the Statue of Liberty and Central Park, to world-class museums like the Met and MoMA, to the countless restaurants and bars that are just waiting to be explored... well, you get the idea. New York City has something for everyone! 😄\\n\\nSo there you have it, folks! If you're planning a trip to New York, just remember to pack your sense of humor... and your umbrella, because let's be real, it's always raining in New York. 😉\")"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["#### Модели вызова функций"],"metadata":{"id":"KEmeCL5gY_l2"}},{"cell_type":"markdown","source":["[Модели вызова функций](https://openai.com/blog/function-calling-and-other-api-updates) аналогичны чат-моделям, но с небольшими особенностями. Они тонко настроены для выдачи структурированных данных.\n","\n","Это удобно, когда нужно выполнить вызов API к внешней службе или извлечение."],"metadata":{"id":"244pD9viY_pd"}},{"cell_type":"code","source":["chat = ChatFireworks(model_name=\"accounts/fireworks/models/llama-v2-13b\", temperature=1., fireworks_api_key = fireworks_api_key)\n","\n","output = chat(messages=\n","     [\n","         SystemMessage(content=\"You are an helpful AI bot\"),\n","         HumanMessage(content=\"What’s the weather like in Boston right now?\")\n","     ],\n","     functions=[{\n","         \"name\": \"get_current_weather\",\n","         \"description\": \"Get the current weather in a given location\",\n","         \"parameters\": {\n","             \"type\": \"object\",\n","             \"properties\": {\n","                 \"location\": {\n","                     \"type\": \"string\",\n","                     \"description\": \"The city and state, e.g. San Francisco, CA\"\n","                 },\n","                 \"unit\": {\n","                     \"type\": \"string\",\n","                     \"enum\": [\"celsius\", \"fahrenheit\"]\n","                 }\n","             },\n","             \"required\": [\"location\"]\n","         }\n","     }\n","     ]\n",")\n","output"],"metadata":{"id":"BDYV4vLGY_vt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"34f3c8f8-4e53-4407-9ac2-7385198218be"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"Hello! I'm happy to help! 😊\\n\\nAccording to the latest weather forecast, the current weather in Boston is mostly cloudy with a temperature of around 50°F (10°C). There is a chance of scattered thunderstorms in the area, so it's a good idea to check the weather forecast regularly for updates.\\n\\nHere's the current weather conditions in Boston:\\n\\n* Temperature: 50°F (10°C)\\n* Humidity: 60%\\n* Wind speed: 10 mph (16 km/h)\\n* Conditions: Mostly cloudy\\n\\nI hope this helps! Let me know if you have any other questions. 😊\")"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["#### Модель эмбеддинга текста"],"metadata":{"id":"2oVzcdJrZa2Y"}},{"cell_type":"markdown","source":["**Модель эмбеддинга текста** помогает превратить текст в вектор. В основном используется при сравнении двух фрагментов текста."],"metadata":{"id":"hGdMgG4kZa49"}},{"cell_type":"code","source":["from langchain.embeddings.spacy_embeddings import SpacyEmbeddings\n","\n","embeddings = SpacyEmbeddings()"],"metadata":{"id":"ucgQe0pCZRvE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = \"Hi! It's time for the beach\""],"metadata":{"id":"Xz-jZfqTZr32"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_embedding = embeddings.embed_query(text)\n","print (f\"Here's a sample: {text_embedding[:5]}...\")\n","print (f\"Your embedding is length {len(text_embedding)}\")"],"metadata":{"id":"C7OWFS4KZtCh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"461c3044-b59b-4c22-9968-7180d47ff9b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Here's a sample: [0.016218408942222595, 0.1029607430100441, 0.1271773874759674, -0.21745142340660095, 0.1506521999835968]...\n","Your embedding is length 96\n"]}]},{"cell_type":"markdown","source":["### Промпт — текст, обычно используемый в качестве инструкций для модели"],"metadata":{"id":"vcIREqCfZwtR"}},{"cell_type":"markdown","source":["#### Промпт"],"metadata":{"id":"oErd8Ar-Zw4-"}},{"cell_type":"markdown","source":["Что передается в базовую модель:"],"metadata":{"id":"zCkSj1ptZxLt"}},{"cell_type":"code","source":["from langchain.llms.fireworks import Fireworks\n","\n","llm = Fireworks(model_name=\"accounts/fireworks/models/llama-v2-13b\", fireworks_api_key = fireworks_api_key)\n","\n","# I like to use three double quotation marks for my prompts because it's easier to read\n","prompt = \"\"\"\n","Today is Monday, tomorrow is Wednesday.\n","\n","What is wrong with that statement?\n","\"\"\"\n","\n","print(llm(prompt))"],"metadata":{"id":"G0KMrLAnZxUA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"46c51d38-d050-4120-aad6-c9f843031588"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","HINT: Think about the days of the week.\n"]}]},{"cell_type":"markdown","source":["#### Шаблон промпта"],"metadata":{"id":"ocdzEsvWZ94_"}},{"cell_type":"markdown","source":["**Шаблон промта** — объект, который помогает создавать промпты на основе комбинации вводимых пользователем данных, другой нестатической информации и фиксированной строки шаблона.\n","\n","Предлагаем думать об этом как о f-строке в Python, но для промптов."],"metadata":{"id":"xJoK6hMDZ-Pw"}},{"cell_type":"code","source":["from langchain import PromptTemplate\n","from langchain.llms.fireworks import Fireworks\n","\n","llm = Fireworks(model_name=\"accounts/fireworks/models/llama-v2-13b\", fireworks_api_key = fireworks_api_key)\n","\n","# Notice \"location\" below, that is a placeholder for another value later\n","template = \"\"\"\n","I really want to travel to {location}. What should I do there?\n","\n","Respond in one short sentence\n","\"\"\"\n","\n","prompt = PromptTemplate(\n","    input_variables=[\"location\"],\n","    template=template,\n",")\n","\n","final_prompt = prompt.format(location='Rome')\n","\n","print (f\"Final Prompt: {final_prompt}\")\n","print (\"-----------\")\n","print (f\"LLM Output: {llm(final_prompt)}\")"],"metadata":{"id":"JUJnKb4rZ-V2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"232d35f5-ddcf-4a06-af13-692ca996b362"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Prompt: \n","I really want to travel to Rome. What should I do there?\n","\n","Respond in one short sentence\n","\n","-----------\n","LLM Output: \n","Go to the Colosseum, the Pantheon, and the Vatican City to see some of the ancient history of Rome. \n"]}]},{"cell_type":"markdown","source":["#### Селектор примеров"],"metadata":{"id":"TrjYEA4daT-Y"}},{"cell_type":"markdown","source":["**Селектор примеров** — простой способ выбора из серии примеров, позволяющий динамически размещать контекстную информацию в промпте. Часто используется, когда задача имеет нюансы или есть большой список примеров.\n","\n","Ознакомиться с различными типами примеров селекторов можно в статье [Example selectors](https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/).\n","\n","Узнать более подробно, почему примеры важны (быстрое проектирование), можно в видео [Prompt Engineering Overview](https://www.youtube.com/watch?v=dOxUroR57xs&ab_channel=ElvisSaravia)."],"metadata":{"id":"dcANQ-o5aUBR"}},{"cell_type":"code","source":["from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n","from langchain.vectorstores import Chroma\n","from langchain.embeddings import SpacyEmbeddings\n","from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n","from langchain.llms.fireworks import Fireworks\n","\n","llm = Fireworks(model_name=\"accounts/fireworks/models/llama-v2-13b\", fireworks_api_key = fireworks_api_key)\n","\n","example_prompt = PromptTemplate(\n","    input_variables=[\"input\", \"output\"],\n","    template=\"Example Input: {input}\\nExample Output: {output}\",\n",")\n","\n","# Examples of locations that nouns are found\n","examples = [\n","    {\"input\": \"pirate\", \"output\": \"ship\"},\n","    {\"input\": \"pilot\", \"output\": \"plane\"},\n","    {\"input\": \"driver\", \"output\": \"car\"},\n","    {\"input\": \"tree\", \"output\": \"ground\"},\n","    {\"input\": \"bird\", \"output\": \"nest\"},\n","]"],"metadata":{"id":"44ojP2phaUHG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install chromadb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"maB9Gdgxoy-W","outputId":"99eece73-e937-4357-9e4d-52db6a5fdeb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting chromadb\n","  Downloading chromadb-0.4.15-py3-none-any.whl (479 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.8/479.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.13)\n","Collecting chroma-hnswlib==0.7.3 (from chromadb)\n","  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n","  Downloading fastapi-0.104.0-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n","  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n","  Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.5.0)\n","Collecting pulsar-client>=3.1.0 (from chromadb)\n","  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n","  Downloading onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_api-1.20.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.20.0-py3-none-any.whl (18 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_sdk-1.20.0-py3-none-any.whl (103 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pypika>=0.48.9 (from chromadb)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.1)\n","Collecting overrides>=7.3.1 (from chromadb)\n","  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.0)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.59.0)\n","Collecting bcrypt>=4.0.1 (from chromadb)\n","  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n","Collecting kubernetes>=28.1.0 (from chromadb)\n","  Downloading kubernetes-28.1.0-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n","Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.5)\n","Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.7.1)\n","Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.95.2->chromadb)\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions>=4.5.0 (from chromadb)\n","  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2023.7.22)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n","Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (6.0.1)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.17.3)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.6.4)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n","Collecting urllib3<2.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n","  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n","Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (6.8.0)\n","Collecting backoff<3.0.0,>=1.10.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.61.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.20.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.20.0-py3-none-any.whl (17 kB)\n","Collecting opentelemetry-proto==1.20.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_proto-1.20.0-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-semantic-conventions==0.41b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n","  Downloading opentelemetry_semantic_conventions-0.41b0-py3-none-any.whl (26 kB)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.4)\n","Collecting huggingface_hub<0.18,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n","Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.1.3)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.14.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.12.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.0)\n","Building wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=661e798a908ef4da0b859fdbd6c9aa6645ac0bc217928148bcc14818ff15bdf0\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built pypika\n","Installing collected packages: pypika, monotonic, websockets, uvloop, urllib3, typing-extensions, python-dotenv, pulsar-client, overrides, opentelemetry-semantic-conventions, opentelemetry-proto, humanfriendly, httptools, deprecated, chroma-hnswlib, bcrypt, backoff, watchfiles, uvicorn, starlette, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, posthog, opentelemetry-sdk, onnxruntime, huggingface_hub, fastapi, tokenizers, opentelemetry-exporter-otlp-proto-grpc, kubernetes, chromadb\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.0.7\n","    Uninstalling urllib3-2.0.7:\n","      Successfully uninstalled urllib3-2.0.7\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-4.0.1 chroma-hnswlib-0.7.3 chromadb-0.4.15 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.104.0 httptools-0.6.1 huggingface_hub-0.17.3 humanfriendly-10.0 kubernetes-28.1.0 monotonic-1.6 onnxruntime-1.16.1 opentelemetry-api-1.20.0 opentelemetry-exporter-otlp-proto-common-1.20.0 opentelemetry-exporter-otlp-proto-grpc-1.20.0 opentelemetry-proto-1.20.0 opentelemetry-sdk-1.20.0 opentelemetry-semantic-conventions-0.41b0 overrides-7.4.0 posthog-3.0.2 pulsar-client-3.3.0 pypika-0.48.9 python-dotenv-1.0.0 starlette-0.27.0 tokenizers-0.14.1 typing-extensions-4.8.0 urllib3-1.26.18 uvicorn-0.23.2 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{}}]},{"cell_type":"code","source":["# SemanticSimilarityExampleSelector will select examples that are similar to your input by semantic meaning\n","\n","example_selector = SemanticSimilarityExampleSelector.from_examples(\n","    # This is the list of examples available to select from.\n","    examples,\n","\n","    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n","    SpacyEmbeddings(),\n","\n","    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n","    Chroma,\n","\n","    # This is the number of examples to produce.\n","    k=2\n",")"],"metadata":{"id":"FVfDlMBravxM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["similar_prompt = FewShotPromptTemplate(\n","    # The object that will help select examples\n","    example_selector=example_selector,\n","\n","    # Your prompt\n","    example_prompt=example_prompt,\n","\n","    # Customizations that will be added to the top and bottom of your prompt\n","    prefix=\"Give the location an item is usually found in\",\n","    suffix=\"Input: {noun}\\nOutput:\",\n","\n","    # What inputs your prompt will receive\n","    input_variables=[\"noun\"],\n",")"],"metadata":{"id":"12VEjMSWa7yt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Select a noun!\n","my_noun = \"plant\"\n","# my_noun = \"student\"\n","\n","print(similar_prompt.format(noun=my_noun))"],"metadata":{"id":"CwXj_Elya71R","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b1ca1aaf-5a22-4196-8806-1fb3a07900c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Give the location an item is usually found in\n","\n","Example Input: pirate\n","Example Output: ship\n","\n","Example Input: driver\n","Example Output: car\n","\n","Input: plant\n","Output:\n"]}]},{"cell_type":"code","source":["llm(similar_prompt.format(noun=my_noun))"],"metadata":{"id":"LcB6sLpxa_CK","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"9a503d34-62c6-4a5c-8734-1cdfc8647730"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' garden'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["#### Метод парсера вывода: инструкции и парсинг строк"],"metadata":{"id":"Raez_Fz5bBL1"}},{"cell_type":"markdown","source":["Полезный способ форматировать выходные данные модели. Обычно используется для структурированного вывода. У LangChain есть еще несколько парсеров вывода, они перечислены в [документации](https://python.langchain.com/docs/modules/model_io/output_parsers).\n","\n","Две большие концепции:\n","\n","1. **Инструкции по форматированию** — автоматически создаваемое приглашение, которое сообщает LLM, как форматировать ответ в зависимости от желаемого результата.\n","\n","2. **Парсер** — метод, который извлекает текстовый вывод модели в желаемую структуру (обычно json)."],"metadata":{"id":"QCqyNQwbbBO4"}},{"cell_type":"code","source":["from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n","from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n","from langchain.llms.fireworks import Fireworks"],"metadata":{"id":"gUgqn_y7bBUp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm = Fireworks(model_name=\"accounts/fireworks/models/llama-v2-13b\", fireworks_api_key = fireworks_api_key)"],"metadata":{"id":"BPAIfCRmb-JJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How you would like your response structured. This is basically a fancy prompt template\n","response_schemas = [\n","    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n","    ResponseSchema(name=\"good_string\", description=\"This is your response, a reformatted response\")\n","]\n","\n","# How you would like to parse your output\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"],"metadata":{"id":"wWd_mSi8b-L_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# See the prompt template you created for formatting\n","format_instructions = output_parser.get_format_instructions()\n","print(format_instructions)"],"metadata":{"id":"_uy5cogCcCiq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab2cd3c3-1ae8-4fd0-897a-57a74526b206"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n","\n","```json\n","{\n","\t\"bad_string\": string  // This a poorly formatted user input string\n","\t\"good_string\": string  // This is your response, a reformatted response\n","}\n","```\n"]}]},{"cell_type":"code","source":["template = \"\"\"\n","You will be given a poorly formatted string from a user.\n","Reformat it and make sure all the words are spelled correctly\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","prompt = PromptTemplate(\n","    input_variables=[\"user_input\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n","    template=template\n",")\n","\n","promptValue = prompt.format(user_input=\"welcom to califonya!\")\n","\n","print(promptValue)"],"metadata":{"id":"dP2dJwu3cD8q","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c30ad9a5-e76f-4bd5-9363-4ed7f96951e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","You will be given a poorly formatted string from a user.\n","Reformat it and make sure all the words are spelled correctly\n","\n","The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n","\n","```json\n","{\n","\t\"bad_string\": string  // This a poorly formatted user input string\n","\t\"good_string\": string  // This is your response, a reformatted response\n","}\n","```\n","\n","% USER INPUT:\n","welcom to califonya!\n","\n","YOUR RESPONSE:\n","\n"]}]},{"cell_type":"code","source":["llm_output = llm(promptValue)\n","llm_output"],"metadata":{"id":"A1fdo-ywcFhL","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"368cc67f-9e50-4c27-80ac-69046888def1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'```json\\n{\\n\\t\"bad_string\": \"welcom to califonya!\",\\n\\t\"good_string\": \"Welcome to California!\"\\n}\\n```\\nPlease input a string:'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["output_parser.parse(llm_output)"],"metadata":{"id":"jwsNjUKfcGo9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"65ba981f-3a1c-4987-93a5-76cc65bac789"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bad_string': 'welcom to califonya!', 'good_string': 'Welcome to California!'}"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["### Индексы — с ними могут работать структурирующие документы для LLM"],"metadata":{"id":"YPYhnZqBdkAF"}},{"cell_type":"markdown","source":["#### Загрузчики документов"],"metadata":{"id":"Ydntbly2eB_k"}},{"cell_type":"markdown","source":["Простые способы импорта данных из других источников. Общая функциональность с [плагинами OpenAI, в частности с плагинами поиска](https://github.com/openai/chatgpt-retrieval-plugin).\n","\n","[Большой список загрузчиков документов](https://python.langchain.com/docs/modules/data_connection/document_loaders.html).\n","\n","Еще немного об [Llama Index](https://llamahub.ai/)."],"metadata":{"id":"a7t00GhAeF-k"}},{"cell_type":"markdown","source":["**Хакерские новости**"],"metadata":{"id":"y1AZgeftedIR"}},{"cell_type":"code","source":["from langchain.document_loaders import HNLoader"],"metadata":{"id":"hmTq7WB-eb6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loader = HNLoader(\"https://news.ycombinator.com/item?id=34422627\")"],"metadata":{"id":"ZzV5xGM8efDn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = loader.load()"],"metadata":{"id":"tlNMFDVHegde"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print (f\"Found {len(data)} comments\")\n","print (f\"Here's a sample:\\n\\n{''.join([x.page_content[:150] for x in data[:2]])}\")"],"metadata":{"id":"8ZPA21ZxeimG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f00b8578-c650-413f-c046-db9967f872a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 76 comments\n","Here's a sample:\n","\n","Ozzie_osman 9 months ago  \n","             | next [–] \n","\n","LangChain is awesome. For people not sure what it's doing, large language models (LLMs) are very Ozzie_osman 9 months ago  \n","             | parent | next [–] \n","\n","Also, another library to check out is GPT Index (https://github.com/jerryjliu/gpt_index)\n"]}]},{"cell_type":"markdown","source":["**Книги из проекта Гутенберга**"],"metadata":{"id":"CSZm9o2qenLz"}},{"cell_type":"code","source":["from langchain.document_loaders import GutenbergLoader\n","\n","loader = GutenbergLoader(\"https://www.gutenberg.org/cache/epub/2148/pg2148.txt\")\n","\n","data = loader.load()"],"metadata":{"id":"wbUdkgcvekL2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(data[0].page_content[1855:1984])"],"metadata":{"id":"0nB_GeU8emSo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"742c8e99-35ce-46d2-c4ef-f5d0bfbb963c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      At Paris, just after dark one gusty evening in the autumn of 18-,\r\n","\n","\n","      I was enjoying the twofold luxury of meditation \n"]}]},{"cell_type":"markdown","source":["**Веб-страницы и URL-адреса**"],"metadata":{"id":"mGrqYAiwqr3r"}},{"cell_type":"code","source":["!pip install unstructured"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cpd8VjjIuUEq","outputId":"b5a54738-cbd2-4b2e-a12b-3512f47d59a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting unstructured\n","  Downloading unstructured-0.10.27-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n","Collecting filetype (from unstructured)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Collecting python-magic (from unstructured)\n","  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.3)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.11.2)\n","Collecting emoji (from unstructured)\n","  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.1)\n","Collecting python-iso639 (from unstructured)\n","  Downloading python_iso639-2023.6.15-py3-none-any.whl (275 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.1/275.1 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langdetect (from unstructured)\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.23.5)\n","Collecting rapidfuzz (from unstructured)\n","  Downloading rapidfuzz-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.8.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.20.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (4.66.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2023.7.22)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n","Building wheels for collected packages: langdetect\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=d6723fb6ce51c982e5b015a617f74bee69f66a359729c91dc65da74518673277\n","  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n","Successfully built langdetect\n","Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, langdetect, emoji, unstructured\n","Successfully installed emoji-2.8.0 filetype-1.2.0 langdetect-1.0.9 python-iso639-2023.6.15 python-magic-0.4.27 rapidfuzz-3.4.0 unstructured-0.10.27\n"]}]},{"cell_type":"code","source":["from langchain.document_loaders import UnstructuredURLLoader\n","\n","urls = [\n","    \"http://www.paulgraham.com/\",\n","]\n","\n","loader = UnstructuredURLLoader(urls=urls)\n","\n","data = loader.load()\n","\n","data[0].page_content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"TL2FjoF4qq4w","outputId":"0b7f2ed7-08d7-49d0-dd4f-62125faff6a8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'New:  \\r\\n\\r\\n Superlinear Returns  |\\r\\n How to Do Great Work \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n Want to start a startup?  Get funded by  Y Combinator .\\r\\n \\r\\n \\r\\n \\r\\n\\r\\n \\n\\r\\n \\r\\n \\r\\n \\r\\n© mmxxiii pg'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["### Память"],"metadata":{"id":"wTz04rGdinCm"}},{"cell_type":"markdown","source":["Помощь LLM в запоминании информации.\n","\n","Память — довольно расплывчатый термин. Это может быть простое запоминание информации, о которой говорили в прошлом, или более сложный поиск информации.\n","\n","Мы оставим его для варианта использования сообщений чата. Это будет использоваться для чат-ботов.\n","\n","Существует множество типов памяти. Изучите [документацию](https://python.langchain.com/docs/modules/memory/), чтобы определить, какой из них подходит для вашего случая использования."],"metadata":{"id":"juAucPGKioC-"}},{"cell_type":"markdown","source":["#### История сообщений чата"],"metadata":{"id":"Ed2AZ0tAi6Y3"}},{"cell_type":"code","source":["from langchain.memory import ChatMessageHistory\n","from langchain.chat_models import ChatFireworks\n","\n","chat = ChatFireworks(temperature=0, fireworks_api_key=fireworks_api_key)\n","\n","history = ChatMessageHistory()\n","\n","\n","history.add_user_message(\"hi!\")\n","history.add_ai_message(\"Hi!\")\n","history.add_user_message(\"what is the capital of france?\")"],"metadata":{"id":"hU5z3Ajii70_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history.messages"],"metadata":{"id":"3vh2w4VBi8D4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c15196be-5d38-4116-eece-f0722ec452b5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content='hi!'),\n"," AIMessage(content='Hi!'),\n"," HumanMessage(content='what is the capital of france?')]"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["ai_response = chat(history.messages)\n","ai_response"],"metadata":{"id":"tVeGDpPji9D_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"526cd0d4-bdb1-43b3-e260-96937d45022f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='The capital of France is Paris.')"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["history.add_ai_message(ai_response.content)\n","history.messages"],"metadata":{"id":"hTuraRaBi-J4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"63a45657-909c-429f-85be-8848d4f52c45"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content='hi!'),\n"," AIMessage(content='Hi!'),\n"," HumanMessage(content='what is the capital of france?'),\n"," AIMessage(content='The capital of France is Paris.')]"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["### Цепочки ⛓️"],"metadata":{"id":"tJ9v321XjCfv"}},{"cell_type":"markdown","source":["**Цепочки** — автоматическое объединение различных вызовов и действий LLM.\n","\n","Пример: Саммари №1, Саммари №2, Саммари №3 —> Итоговое саммари.\n","\n","Посмотрите [видео](https://www.youtube.com/watch?v=f9_BWhCI4Zo&t=2s&ab_channel=GregKamradt%28DataIndy%29), где объясняются различные типы цепочек реферирования.\n","\n","Существует множество приложений цепочек. Изучите [материал](https://python.langchain.com/docs/modules/chains), чтобы определить, какие из них лучше всего подходят для вашего случая использования.\n","\n","Мы поговорим о дввух из них подробнее."],"metadata":{"id":"XY3VQG5sjGtB"}},{"cell_type":"markdown","source":["#### Простые последовательные цепочки"],"metadata":{"id":"C1bCiJwZjkay"}},{"cell_type":"markdown","source":["Простые цепочки, в которых можно использовать выходные данные одного LLM в качестве входных данных для другого. Хорошо подходит для разделения задач (и сохранения сосредоточенности вашего LLM)."],"metadata":{"id":"2utS38Lcjo9E"}},{"cell_type":"code","source":["from langchain.llms.fireworks import Fireworks\n","from langchain.chains import LLMChain\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import SimpleSequentialChain\n","\n","llm = Fireworks(temperature=1, fireworks_api_key=fireworks_api_key)"],"metadata":{"id":"BrR_IrtFi___"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["template = \"\"\"Your job is to come up with a classic dish from the area that the users suggests.\n","% USER LOCATION\n","{user_location}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","prompt_template = PromptTemplate(input_variables=[\"user_location\"], template=template)\n","\n","# Holds my 'location' chain\n","location_chain = LLMChain(llm=llm, prompt=prompt_template)"],"metadata":{"id":"hLt73iWYjrtD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["template = \"\"\"Given a meal, give a short and simple recipe on how to make that dish at home.\n","% MEAL\n","{user_meal}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","prompt_template = PromptTemplate(input_variables=[\"user_meal\"], template=template)\n","\n","# Holds my 'meal' chain\n","meal_chain = LLMChain(llm=llm, prompt=prompt_template)"],"metadata":{"id":"IgqtoFaGjtKp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)"],"metadata":{"id":"4NG_hlF5jugB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["review = overall_chain.run(\"Rome\")"],"metadata":{"id":"PObfHv-Ijvmi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9816ed8-1213-437c-8d82-4d46e96979a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n","\u001b[36;1m\u001b[1;3mPasta Carbonara! This classic Roman dish is a staple of Italian cuisine and a must-try when visiting Rome. Made with spaghetti, bacon or pancetta, eggs, and Parmesan cheese, it's creamy, rich, and utterly delicious. Buon appetito!\u001b[0m\n","\u001b[33;1m\u001b[1;3m\n","To make Pasta Carbonara at home, start by cooking spaghetti according to package instructions until it's al dente. While the spaghetti cooks, heat a few strips of bacon or pancetta in a pan until crispy. Remove the bacon from the pan and set it aside on a paper towel-lined plate. In the same pan, add 2-3 eggs and a sprinkle of salt and pepper. Stir the eggs constantly over medium heat until they're cooked through and slightly thickened. Add the cooked spaghetti to the pan with the eggs and toss everything together until the pasta is well coated. Finally, add the cooked bacon back into the pan and toss everything together once more. Serve immediately, topped with grated Parmesan cheese and a sprinkle of parsley for garnish. Enjoy!\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]}]},{"cell_type":"markdown","source":["### Вывод\n","\n","В этом семинаре мы познакомились с библиотекой LangChain, которая позволяет делать из языковых моделей настоящие продуктовые решения. С удовольствием применяйте ее на практике :)\n","\n","Это последний семинар. Спасибо, что прослушали курс :)"],"metadata":{"id":"ydBR7HII-tjL"}}]}