$$![Rick](https://github.com/NeKonnnn/MIPT_HW/assets/91149797/1e8e4e02-eae1-4ab7-9eef-1004332caf86)$$

# Сбор данных:
Dataset был взят с Kaggle: https://www.kaggle.com/datasets/zerofactorialisone/rick-and-morty-discord-chatbot-dataset и в ходе разработки моделей претерпел некоторые изменения! Изначально датасет был на английском языке, но я захотел, чтобы мой бот Рик был русскоязычным, поэтому, для того чтобы сократить время на перевод я воспользовался нейронной сетью DeepL Translate, и сохранил результат в docx формат. Далее была проведена предобработка данных в ноутбуке EDA.ipynb. Для установления характера Рика, я выяснил, какими словами он пользуется чаще всего, а также обратил внимание на манеру его речи и ведение диалога! После этого сформировал итоговый датасет, который находится в папке data\data_OUT\rick.csv

# Разработка модели:
При разработке было построено 2 модели:
Первая модель была построена на принципе bag_of_words и содержится в bag_of_words_model.ipynb, а вторая модель была построена на основе cross_encoder и содержится в файле cross_encoder_model.py. Была взята за основу предобученная модель bert-base-uncased.
Результаты обучения второй модели: 
![image](https://github.com/NeKonnnn/MIPT_HW/assets/91149797/0e940395-1ca1-4719-bb65-f72c96c23792)
![image](https://github.com/NeKonnnn/MIPT_HW/assets/91149797/3a500941-44a1-420b-a302-a1032ad8d175)

## Выводы по результатам модели:
Данные результаты указывают на очень высокую эффективность модели в процессе обучения и валидации. Стабильная точность 100% на обучающем и валидационном наборах данных может свидетельствовать о следующем:
1.	Переобучение: модель идеально подстроилась под тренировочные данные, что может привести к снижению ее способности к обобщению на новых данных. Однако стабильно высокая точность на валидационном наборе может говорить о том, что данные хорошо представляют общую закономерность, которую модель смогла выучить.
2.	Качество данных: возможно, датасет не достаточно разнообразен или слишком мал, что позволяет модели легко достичь высокой точности. В таком случае, важно обеспечить большую вариативность и объем обучающих данных.
Я склонен придерживаться второго мнения, т.к. итоговый набор данных действительно не большой. В силу отсутствия времени больший набор собрать не удалось!

# Код инференса модели:
![image](https://github.com/NeKonnnn/MIPT_HW/assets/91149797/3a58ecbf-0ee4-4766-94c0-103544a1a6a7)

При тестировании модели на примере вопроса "Как тебя зовут?", модель смогла с высокой уверенностью (98%) выбрать подходящий ответ, что свидетельствует о хорошей способности модели обрабатывать естественный язык и выдавать релевантные ответы на поставленные вопросы.

# Ускорение инференса модели:
![image](https://github.com/NeKonnnn/MIPT_HW/assets/91149797/4147650c-824c-4366-a205-b2f49b9d3122)

После процесса квантования модели, точность на валидационном наборе данных осталась стабильно высокой (100%). Это говорит о том, что квантование не оказало заметного негативного влияния на производительность модели, что является значительным достижением, учитывая сокращение занимаемых ресурсов и увеличение скорости инференса.
 

# Запуск бота:
Данный процесс реализован через FastAPI.
Чтобы запустить бота, нужно:
1. установить ngrok.exe с сайта https://ngrok.com/ локально на ПК
2. зарегистрироваться
3. после установки в появившемся окне Your Authtoken
4. в файле settings.py WEBHOOK_HOST на ваш token
5. Далее запустить файл my_main.py

После этого можно найти в телеграмме бота rick_pickle_bot и общаться с ним!
![image](https://github.com/NeKonnnn/MIPT_HW/assets/91149797/7ed04e75-0182-457a-ab56-325c4d3f964c)

# Заключение
На основе проведенного анализа можно сделать вывод о высокой эффективности разработанной модели для задачи автоматизированного чат-бота. Однако для обеспечения более глубокого понимания ее способностей и ограничений необходимо провести дополнительные эксперименты, включая тестирование на более разнообразном и объемном наборе данных, а также оценку способности модели к обобщению на новых, невиданных примерах.

