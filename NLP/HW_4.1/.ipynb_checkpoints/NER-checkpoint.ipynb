{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586afb66",
   "metadata": {},
   "source": [
    "# Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7854a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import pytest\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "\n",
    "from transformers import AutoTokenizer \n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28db3ec3",
   "metadata": {},
   "source": [
    "# Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "196e98b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename: str, encoding: str = 'utf-8') -> str:\n",
    "    \"\"\"\n",
    "    Функция для чтения содержимого файла.\n",
    "    \n",
    "    :param filename: Имя файла или путь к файлу, который нужно прочитать.\n",
    "    :param encoding: Кодировка файла (используем 'utf-8' для нашей задачи).\n",
    "    :return: Строка с содержимым файла.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r', encoding=encoding) as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49eb7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = read_file('train.txt')\n",
    "val_txt = read_file('dev.txt')\n",
    "test_txt =  read_file('test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206b665",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6605382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_to_dataframe(text: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Преобразование входного текста в DataFrame.\n",
    "    '''\n",
    "    # Разбиваем текст на строки\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    # Списки для хранения предложений и меток\n",
    "    all_sentences, all_tags = [], []\n",
    "    \n",
    "    # Временные списки для текущего предложения и меток\n",
    "    current_sentence, current_tags = [], []\n",
    "    \n",
    "    for line in lines:\n",
    "        if line:  # Если строка не пустая\n",
    "            word, tag_value = line.split(' ')\n",
    "            current_sentence.append(word)\n",
    "            current_tags.append(tag_value)\n",
    "        else:  # Если строка пустая, то это конец текущего предложения\n",
    "            all_sentences.append(current_sentence)\n",
    "            all_tags.append(current_tags)\n",
    "            current_sentence, current_tags = [], []\n",
    "    \n",
    "    # Создаём DataFrame\n",
    "    df = pd.DataFrame({'Words': all_sentences, 'Tags': all_tags})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f81c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocess_text_to_dataframe(train_txt)\n",
    "val_data = preprocess_text_to_dataframe(val_txt)\n",
    "test_data = preprocess_text_to_dataframe(test_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cd84a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_data': (7747, 2), 'val_data': (2583, 2), 'test_data': (2583, 2)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Объединение датафреймов в словарь\n",
    "dataframes = {\n",
    "    'train_data': train_data,\n",
    "    'val_data': val_data,\n",
    "    'test_data': test_data\n",
    "}\n",
    "\n",
    "# Вывод размерностей каждого датафрейма\n",
    "dimensions = {key: df.shape for key, df in dataframes.items()}\n",
    "dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64837222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\", Если, Миронов, занял, столь, оппозиционную...</td>\n",
       "      <td>[O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Источник, \", Ъ, '', в, руководстве, столичной...</td>\n",
       "      <td>[O, O, B-ORG, O, O, O, O, O, O, O, O, O, O, B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[В, Ханты-Мансийском, автономном, округе, с, д...</td>\n",
       "      <td>[O, B-LOC, I-LOC, I-LOC, O, O, O, O, B-ORG, B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[С, 1992, года, по, настоящее, время, является...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Для, этого, ей, пришлось, выиграть, выборы, в...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-LOC, I-LOC, O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Words  \\\n",
       "0  [\", Если, Миронов, занял, столь, оппозиционную...   \n",
       "1  [Источник, \", Ъ, '', в, руководстве, столичной...   \n",
       "2  [В, Ханты-Мансийском, автономном, округе, с, д...   \n",
       "3  [С, 1992, года, по, настоящее, время, является...   \n",
       "4  [Для, этого, ей, пришлось, выиграть, выборы, в...   \n",
       "\n",
       "                                                Tags  \n",
       "0  [O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O,...  \n",
       "1  [O, O, B-ORG, O, O, O, O, O, O, O, O, O, O, B-...  \n",
       "2  [O, B-LOC, I-LOC, I-LOC, O, O, O, O, B-ORG, B-...  \n",
       "3  [O, O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, B-LOC, I-LOC, O...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06d0adcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-LOC', 'I-ORG', 'I-PER', 'B-ORG', 'B-PER', 'B-LOC', 'O']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_unique_tags(df):\n",
    "    \"\"\"\n",
    "    Извлекает уникальные теги из столбца 'Tags' датафрейма.\n",
    "\n",
    "    Параметры:\n",
    "    - df (pd.DataFrame): Датафрейм, содержащий столбец 'Tags' со списками тегов.\n",
    "    \"\"\"\n",
    "    \n",
    "    ner_tags = []  # Инициализация пустого списка для тегов\n",
    "\n",
    "    # Проход по каждому списку тегов в датафрейме\n",
    "    for tags_list in df['Tags']:\n",
    "        # Добавление каждого тега в список ner_tags\n",
    "        for tag in tags_list:\n",
    "            ner_tags.append(tag)\n",
    "\n",
    "    # Удаление дубликатов путем преобразования в множество и обратно в список\n",
    "    ner_tags = list(set(ner_tags))\n",
    "\n",
    "    return ner_tags\n",
    "\n",
    "unique_tags = extract_unique_tags(train_data)\n",
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd069e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Словарь 1: {'I-LOC': 0, 'I-ORG': 1, 'I-PER': 2, 'B-ORG': 3, 'B-PER': 4, 'B-LOC': 5, 'O': 6}\n",
      "Словарь 2: {0: 'I-LOC', 1: 'I-ORG', 2: 'I-PER', 3: 'B-ORG', 4: 'B-PER', 5: 'B-LOC', 6: 'O'}\n"
     ]
    }
   ],
   "source": [
    "def create_label_mappings(df):\n",
    "    \"\"\"\n",
    "    Извлекает уникальные теги из датафрейма и создает два словаря:\n",
    "    tag_to_index (метка -> индекс) и index_to_tag (индекс -> метка).\n",
    "\n",
    "    Параметры:\n",
    "    - df (pd.DataFrame): Датафрейм, содержащий столбец 'Tags' со списками тегов.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Извлечение уникальных тегов\n",
    "    unique_tags = extract_unique_tags(df)\n",
    "    \n",
    "    # Создание словаря tag_to_index\n",
    "    tag_to_index = dict(zip(unique_tags, range(len(unique_tags))))\n",
    "    \n",
    "    # Создание обратного словаря index_to_tag\n",
    "    index_to_tag = {v: k for k, v in tag_to_index.items()}\n",
    "    \n",
    "    return tag_to_index, index_to_tag\n",
    "\n",
    "tag_to_index, index_to_tag = create_label_mappings(train_data)\n",
    "print(f'Словарь 1: {tag_to_index}')\n",
    "print(f'Словарь 2: {index_to_tag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c669969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\", Если, Миронов, занял, столь, оппозиционную...</td>\n",
       "      <td>[6, 6, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Источник, \", Ъ, '', в, руководстве, столичной...</td>\n",
       "      <td>[6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[В, Ханты-Мансийском, автономном, округе, с, д...</td>\n",
       "      <td>[6, 5, 0, 0, 6, 6, 6, 6, 3, 4, 2, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[С, 1992, года, по, настоящее, время, является...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 3, 1, 1, 6, 1, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Для, этого, ей, пришлось, выиграть, выборы, в...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 0, 6, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Words  \\\n",
       "0  [\", Если, Миронов, занял, столь, оппозиционную...   \n",
       "1  [Источник, \", Ъ, '', в, руководстве, столичной...   \n",
       "2  [В, Ханты-Мансийском, автономном, округе, с, д...   \n",
       "3  [С, 1992, года, по, настоящее, время, является...   \n",
       "4  [Для, этого, ей, пришлось, выиграть, выборы, в...   \n",
       "\n",
       "                                                Tags  \n",
       "0  [6, 6, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...  \n",
       "1  [6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, ...  \n",
       "2               [6, 5, 0, 0, 6, 6, 6, 6, 3, 4, 2, 6]  \n",
       "3  [6, 6, 6, 6, 6, 6, 6, 6, 3, 1, 1, 6, 1, 6, 6, ...  \n",
       "4         [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 0, 6, 6]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_encode(labels):\n",
    "    \"\"\"\n",
    "    Преобразует список меток в список соответствующих идентификаторов \n",
    "    с помощью словаря tag_to_index.\n",
    "\n",
    "    Параметры:\n",
    "    - labels (list): Список меток.\n",
    "\n",
    "    Возвращает:\n",
    "    - list: Список идентификаторов.\n",
    "    \"\"\"\n",
    "    new_labels = [tag_to_index[label] for label in labels]\n",
    "    return new_labels\n",
    "\n",
    "# Применяем функцию к столбцу 'Tags' каждого датафрейма\n",
    "train_data['Tags'] = train_data['Tags'].apply(label_encode)\n",
    "val_data['Tags'] = val_data['Tags'].apply(label_encode)\n",
    "test_data['Tags'] = test_data['Tags'].apply(label_encode)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b93e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование датафреймов в датасеты\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8938f",
   "metadata": {},
   "source": [
    "# Fine-tuning предварительно обученной модели LaBSE от HuggingFace - архитектура BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "864d7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение пути модели\n",
    "model_path = \"surdan/LaBSE_ner_nerel\"\n",
    "\n",
    "# Инициализация токенизатора\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2538d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для выравнивания меток с токенами\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            label = labels[word_id]\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7132e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для токенизации и выравнивания меток\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples['Words'], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples['Tags']\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    tokenized_inputs['labels'] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7b41167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c034fa31ce04c429ccd941b0c671956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7747 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44608c45ad8e4cdd87aa622e8d6f3a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2583 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59909481854f47de97fed62fc4e0d0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2583 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Применяем функцию к каждому датасету\n",
    "tokenized_train = train_dataset.map(\n",
    "    tokenize_and_align_labels, batched=True, remove_columns=train_dataset.column_names\n",
    ")\n",
    "tokenized_val = val_dataset.map(\n",
    "    tokenize_and_align_labels, batched=True, remove_columns=val_dataset.column_names\n",
    ")\n",
    "tokenized_test = test_dataset.map(\n",
    "    tokenize_and_align_labels, batched=True, remove_columns=test_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e00e15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация инструмента для создания батчей\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "# Создаем словарь для преобразования меток\n",
    "id2label = {i: label for i, label in enumerate(tag_to_index)}\n",
    "label2id = {label: i for i, label in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3cd031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка метрик\n",
    "metric = evaluate.load('seqeval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "355dfe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления метрик\n",
    "def compute_metric(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        'precision': all_metrics['overall_precision'],\n",
    "        'recall'   : all_metrics['overall_recall'],\n",
    "        'f1'       : all_metrics['overall_f1'],\n",
    "        'accuracy' : all_metrics['overall_accuracy'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f91bfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at surdan/LaBSE_ner_nerel and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([58, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([58]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_path, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Параметры обучения\n",
    "training_args = TrainingArguments(\n",
    "    model_path,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11db8532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация тренера\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metric,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce0e3fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2907' max='2907' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2907/2907 03:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.024955</td>\n",
       "      <td>0.967339</td>\n",
       "      <td>0.979380</td>\n",
       "      <td>0.973322</td>\n",
       "      <td>0.993531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.024986</td>\n",
       "      <td>0.977580</td>\n",
       "      <td>0.980123</td>\n",
       "      <td>0.978850</td>\n",
       "      <td>0.994374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>0.977346</td>\n",
       "      <td>0.981795</td>\n",
       "      <td>0.979565</td>\n",
       "      <td>0.994763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2907, training_loss=0.03066817214081367, metrics={'train_runtime': 189.4263, 'train_samples_per_second': 122.691, 'train_steps_per_second': 15.346, 'total_flos': 720615539097696.0, 'train_loss': 0.03066817214081367, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучение модели\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51025e4e",
   "metadata": {},
   "source": [
    "- `Training Loss и Validation Loss`: Модель успешно обучилась, так как потери на тренировочных данных уменьшались с каждой эпохой. Однако стоит обратить внимание, что потери на валидационных данных немного увеличились на второй эпохе, но затем снова уменьшились на третьей. Это может указывать на небольшое переобучение, но разница не критична.\n",
    "- `F1`: Значение 0.97 говорит о высоком качестве нашей модели.\n",
    "\n",
    "Можно сделать вывод, что модель показывает отличные результаты на валидационных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ea06aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Предсказания на тестовом датасете\n",
    "predictions = trainer.predict(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4080b6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.96      0.94      1090\n",
      "           2       0.98      0.99      0.98      4187\n",
      "           3       0.96      0.98      0.97      1734\n",
      "           4       0.97      0.99      0.98      7109\n",
      "           5       0.99      0.98      0.98      1508\n",
      "           6       0.43      1.00      0.60     63781\n",
      "\n",
      "   micro avg       0.48      0.99      0.65     79409\n",
      "   macro avg       0.88      0.98      0.91     79409\n",
      "weighted avg       0.54      0.99      0.68     79409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Извлечение истинных и предсказанных меток\n",
    "labels_true = [l for s in tokenized_test['labels'] for l in s+[-100]*(predictions[0].shape[1] - len(s))]\n",
    "labels_true = [0 if l==-100 else l for l in labels_true]\n",
    "labels_pred = [np.argmax(l) for s in predictions[0] for l in s]\n",
    "\n",
    "# Подсчет метрик\n",
    "classification_report = metrics.classification_report(labels_true, labels_pred, labels=list(id2label.keys())[1:])\n",
    "\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a024215",
   "metadata": {},
   "source": [
    "- Классы 1, 2, 3, 4, 5: Эти классы показывают отличные результаты. Точность, полнота и F1-мера для этих классов находятся на уровне 96%-99%, что говорит о высокой эффективности нашей модели для этих классов.\n",
    "\n",
    "- Класс 6: Этот класс имеет очень высокую полноту 100%, но относительно низкую точность 43%. Это означает, что наша модель почти всегда правильно идентифицирует истинные экземпляры этого класса (отсюда высокая полнота), но также часто ошибочно помечает другие классы как класс 6 (отсюда низкая точность). F1-мера для этого класса составляет 60%, что является средним значением между точностью и полнотой.\n",
    "\n",
    "Среднее значение метрик для каждого класса (macro avg) F1-меры составляет 91% и это говорит о том, что в среднем по всем классам наша модель работает хорошо.\n",
    "Среднее значение метрик для каждого класса (weighted avg), взвешенное по количеству экземпляров в каждом классе F1-меры в 68% указывает на хорошую производительность модели, учитывая распределение классов.\n",
    "\n",
    "**Вывод**: Наша модель показывает отличные результаты для большинства классов. Однако для класса 5 производительность ниже, что может быть связано с несбалансированностью классов или другими факторами. Метрика F1  в среднем достигает 91% для всех классов, что является более чем положительным результатом в рамках домашнего задания.\n",
    "\n",
    "**Общие выводы**: \n",
    "\n",
    "- 1. В коде явно не указано использование lr scheduler. Однако стоит отметить, что TrainingArguments в библиотеке transformers по умолчанию использует lr scheduler. \n",
    "- 2. В коде используется модель surdan/LaBSE_ner_nerel из библиотеки transformers, которая представляет собой одну из современных архитектур для NER. LaBSE (Language-agnostic BERT Sentence Embedding) — это одна из вариаций BERT, предназначенная для создания многоязычных эмбеддингов предложений.\n",
    "- 3. В TrainingArguments указан параметр weight_decay, который является коэффициентом L2-регуляризации. Это помогает предотвратить переобучение модели.\n",
    "- 4. Используется стандартная функция потерь для задачи классификации токенов в AutoModelForTokenClassification. Эта функция потерь обычно основана на кросс-энтропии."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
