{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlGqaxJQNJZM"
      },
      "source": [
        "# Модуль 3. Мультимодальные и мультизадачные модели. Часть 1\n",
        "\n",
        "Это вторая часть домашней работы №3 \"Реализация Visual Question Answering / Document Question Answering\"\n",
        "\n",
        "## Часть 2. Использование модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlE7tLFFqwdb"
      },
      "source": [
        "**Цель:** отработать навыки адаптации готовых моделей для решения прикладной задачи на русском языке, а также создание небольших демо для задач.\n",
        "\n",
        "**В каком виде прислать результат:**\n",
        "\n",
        "заполненный jupyter-notebook и видеозаписи работы с демо"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4kOb23dygOQ"
      },
      "source": [
        "### [2 балла] Добавить модель переводчика\n",
        "\n",
        "У вас уже есть готовая модель, которая может по картинке отвечать на текстовые запросы к картинке. Ваша цель --- обобщить эту модель на русский язык, добавив модель переводчик, которая будет переводить запрос на русском языке в запрос на английском языке и передавать его модели. За основу вы можете взять языковую модель (например, https://huggingface.co/Helsinki-NLP/opus-mt-ru-en). Альтернативой может стать реализация функции, делающий api вызов, к приложению переводчика (например, https://libretranslate.com/).\n",
        "\n",
        "---\n",
        "\n",
        "**Ожидаемый результат**\n",
        "\n",
        "В качестве результата в этой секции вам нужно предоставить функции, которые делают перевод с русского на английского и делает инференс модели DocVQA и выводит ответ на русском языке. (В качестве примеров вопросов, можете использовать данные из датасета)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7b5TIJ1eIJT",
        "outputId": "14fd5b96-f4f3-42fe-9204-11b94cfe21cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets\n",
        "!pip install -q sentencepiece\n",
        "!pip install -q git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
        "!pip install -q opencv-python\n",
        "!pip install -q git+https://github.com/facebookresearch/detectron2.git\n",
        "!pip install -q gradio\n",
        "!pip install -q pillow\n",
        "!pip install -q SpeechRecognition pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "dc3af0e3c97648bdbf2f237e6f191b1b",
            "44b852c4515e4ea9a42c2540822021cd",
            "ce39a0bd8e6d44538dfd26ae1ab25e48",
            "89da2388a2544e908a085e69cd70e61c",
            "51aed6b46e52475eb5ceeb3c214532de",
            "47e7793e71834836943058cc4bead54b",
            "4e7fdbc7703f47f08607b42f9268a403",
            "75dc8f9face444dc92e5fcc677034be8",
            "8d32c6719666484192023a37dba2804e",
            "20f930625be34b1f88faf13660fe1a6d",
            "c77df7d72e5640e9a3dcec73d8ab2681",
            "dd4b7529027347978c18e6388bbacc14",
            "7baca6d3d8554f59b075b5e31438d3f9",
            "970a8336d3ce46528dd505cd72e1a080",
            "7440e09fa22a438db819fb4918bb65a2",
            "4cd259cf7aba493facf9f52a40765cef",
            "da7cbb4ee26d4306aeb3e967a7ebb521"
          ]
        },
        "id": "ilwkoHs5f4Ih",
        "outputId": "32d28029-2742-43dd-aa91-a7cc2c1fb90a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc3af0e3c97648bdbf2f237e6f191b1b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import MarianMTModel\n",
        "from transformers import MarianTokenizer\n",
        "from transformers import LayoutLMv2Processor\n",
        "from transformers import LayoutLMv2ForQuestionAnswering\n",
        "from transformers import LayoutLMv2Tokenizer\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zp9AVZEjxKiT"
      },
      "outputs": [],
      "source": [
        "# Загрузка моделей и токенизаторов для обоих направлений перевода\n",
        "models = {\n",
        "    \"ru-en\": {\n",
        "        \"model_name\": \"Helsinki-NLP/opus-mt-ru-en\",\n",
        "        \"model\": None,\n",
        "        \"tokenizer\": None\n",
        "    },\n",
        "    \"en-ru\": {\n",
        "        \"model_name\": \"Helsinki-NLP/opus-mt-en-ru\",\n",
        "        \"model\": None,\n",
        "        \"tokenizer\": None\n",
        "    }\n",
        "}\n",
        "\n",
        "# Функция инициализации модели и токенизатора (если они еще не были загружены)\n",
        "def load_model_and_tokenizer(direction):\n",
        "    if models[direction][\"model\"] is None or models[direction][\"tokenizer\"] is None:\n",
        "        models[direction][\"model\"] = MarianMTModel.from_pretrained(models[direction][\"model_name\"])\n",
        "        models[direction][\"tokenizer\"] = MarianTokenizer.from_pretrained(models[direction][\"model_name\"])\n",
        "\n",
        "# Функция для перевода текста\n",
        "def translate(text, direction):\n",
        "    load_model_and_tokenizer(direction)\n",
        "    tokenizer = models[direction][\"tokenizer\"]\n",
        "    model = models[direction][\"model\"]\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs)\n",
        "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return translated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey45uaNTxKlW",
        "outputId": "79b30a22-4ae8-4bd2-a490-1b14c51d9bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оригинальный текст RU: Давайте поговорим об искусственном интеллекте!\n",
            "Переведенный текст RU-EN: Let's talk about artificial intelligence!\n",
            "-------------------------------------------------------------------------\n",
            "Оригинальный текст EN: Let's talk about artificial intelligence!\n",
            "Переведенный текст EN-RU: Давайте поговорим об искусственном интеллекте!\n"
          ]
        }
      ],
      "source": [
        "# Проверка функций перевода\n",
        "text_ru = \"Давайте поговорим об искусственном интеллекте!\"\n",
        "text_en = \"Let's talk about artificial intelligence!\"\n",
        "\n",
        "translated_text_ru_en = translate(text_ru, \"ru-en\")\n",
        "translated_text_en_ru = translate(text_en, \"en-ru\")\n",
        "\n",
        "print(\"Оригинальный текст RU:\", text_ru)\n",
        "print(\"Переведенный текст RU-EN:\", translated_text_ru_en)\n",
        "print('-'*73)\n",
        "print(\"Оригинальный текст EN:\", text_en)\n",
        "print(\"Переведенный текст EN-RU:\", translated_text_en_ru)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4AxuAl3fxKrG"
      },
      "outputs": [],
      "source": [
        "# Загрузка модели, процессора и токенезатора\n",
        "model_docvqa = LayoutLMv2ForQuestionAnswering.from_pretrained(\"NeKonnn/layoutlmv2-base-uncased_finetuned_docvqa\")\n",
        "processor_docvqa = LayoutLMv2Processor.from_pretrained(\"NeKonnn/layoutlmv2-base-uncased_finetuned_docvqa\")\n",
        "tokenizer_docvqa = LayoutLMv2Tokenizer.from_pretrained(\"NeKonnn/layoutlmv2-base-uncased_finetuned_docvqa\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mNfXQgIvxKuC"
      },
      "outputs": [],
      "source": [
        "def ru_inference(image_path, question_ru):\n",
        "    '''\n",
        "    Эта функция выполняет обработку изображения и вопроса на русском языке,\n",
        "    использует модель для извлечения ответа на заданный вопрос из изображения,\n",
        "    и возвращает ответ на русском языке.\n",
        "\n",
        "    Параметры:\n",
        "    image_path: путь к изображению, на котором нужно найти ответ.\n",
        "    question_ru: вопрос на русском языке, на который нужно ответить.\n",
        "\n",
        "    Возвращает:\n",
        "    answer_ru: ответ на вопрос, извлеченный из изображения, на русском языке.\n",
        "    '''\n",
        "\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    question_en = translate(question_ru, \"ru-en\")\n",
        "    inputs = processor_docvqa(image, question_en, return_tensors=\"pt\")\n",
        "    outputs = model_docvqa(**inputs)\n",
        "    answer_start_scores = outputs.start_logits\n",
        "    answer_end_scores = outputs.end_logits\n",
        "\n",
        "    # Игнорирование токенов CLS, SEP и PAD для начала и конца ответа\n",
        "    ignore_index = [tokenizer_docvqa.cls_token_id, tokenizer_docvqa.sep_token_id, tokenizer_docvqa.pad_token_id]\n",
        "    answer_start_scores[:, ignore_index] = -float(\"Inf\")\n",
        "    answer_end_scores[:, ignore_index] = -float(\"Inf\")\n",
        "\n",
        "    # Выбор начального и конечного токенов ответа\n",
        "    answer_start = torch.argmax(answer_start_scores)\n",
        "    answer_end = torch.argmax(answer_end_scores) + 1\n",
        "\n",
        "    # Преобразование индексов в токены и очистка от служебных символов\n",
        "    answer_tokens = tokenizer_docvqa.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "    answer_tokens = [token for token in answer_tokens if token not in (tokenizer_docvqa.cls_token, tokenizer_docvqa.sep_token, tokenizer_docvqa.pad_token)]\n",
        "\n",
        "    # Сборка токенов в строку ответа\n",
        "    answer = tokenizer_docvqa.convert_tokens_to_string(answer_tokens)\n",
        "    answer_ru = translate(answer, \"en-ru\")\n",
        "\n",
        "    return answer_ru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOSIJvvuw7tL",
        "outputId": "d487287a-ca10-4482-e2e5-34931b434ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-t_y_60o4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-t_y_60o4\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 337ca3490fa7879ceeeadf6c2b73d67504ff4b4f\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.14.1)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (23.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (0.11.2)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (3.11.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 3s (1,803 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 120874 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers datasets\n",
        "! pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install -q pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaJvYevnxKzT",
        "outputId": "be5edcc7-0818-4dca-904b-b6b8b2d3bdf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ответ: Компьютерные системы или устройства для доступа к информации. Информационные технологии оказывают значительное влияние на нашу повседневную жизнь. Информационные технологии используются всеми предприятиями вплоть до одного человека и местных операций. Глобальные компании используют их для управления данными и модернизации своих процессов. Даже продавцы смартфонов используют для сбора платежей, а уличные исполнители дают имя для сбора пожертвований. Если вы используете таблицу для каталога, который вы покупаете Рождеством, вы используете информационную технологию.\n"
          ]
        }
      ],
      "source": [
        "answer = ru_inference(\"/content/sample_data/text2.jpg\", \"Что такое информационные технологии?\")\n",
        "print(\"Ответ:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXfhzF9c0QoT"
      },
      "source": [
        "### [2 балла] Сделать демо на gradio\n",
        "\n",
        "Модель готова! Теперь было бы круто, если модель можно было захостить и оттестировать на практике. В этом задании вам нужно будет реализовать демо на gradio, которое будет принимать изображение и вопрос, а далее выдавать ответ. Пример демо, аналогично которому вам нужно реализовать модель --- https://huggingface.co/spaces/nielsr/comparing-VQA-models.\n",
        "\n",
        "\n",
        "**Подсказка:**\n",
        "\n",
        "В вкладке `Files` на демо вы можете посмотреть реализацию, там нужно заменить инференс, используемой модели, на инференс нашей модели с переводом\n",
        "\n",
        "\n",
        "**Ожидаемый результат**\n",
        "\n",
        "В качестве результата в этой секции вам нужно код для запуска демо на градио и видеозапись его работы, где реализован описанный выше функционал. Видео прикрепляйте отдельным файлом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aN1WYIX-8o5R"
      },
      "outputs": [],
      "source": [
        "def ru_inference(image, question_ru):\n",
        "    '''\n",
        "    Функция для обработки изображения и вопроса на русском языке,\n",
        "    для извлечения ответа на заданный вопрос с помощью модели документного вопросно-ответного анализа (DocVQA).\n",
        "    Ответ извлекается из текста на изображении и переводится на русский язык.\n",
        "\n",
        "    Параметры:\n",
        "    image: изображение в формате PIL.Image, на котором нужно найти ответ.\n",
        "    question_ru: вопрос на русском языке, на который нужно получить ответ из изображения.\n",
        "\n",
        "    Возвращает:\n",
        "    answer_ru: ответ на вопрос, извлечённый из текста на изображении и переведённый на русский язык.\n",
        "    '''\n",
        "\n",
        "    # Преобразование изображения в тензор PyTorch\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    image = transform(image).unsqueeze(0)\n",
        "\n",
        "\n",
        "    question_en = translate(question_ru, \"ru-en\")\n",
        "    inputs = processor_docvqa(image, question_en, return_tensors=\"pt\")\n",
        "    outputs = model_docvqa(**inputs)\n",
        "    answer_start_scores = outputs.start_logits\n",
        "    answer_end_scores = outputs.end_logits\n",
        "\n",
        "    # Игнорирование служебных токенов при выборе начального и конечного индексов\n",
        "    ignore_index = [tokenizer_docvqa.cls_token_id, tokenizer_docvqa.sep_token_id, tokenizer_docvqa.pad_token_id]\n",
        "    answer_start_scores[:, ignore_index] = -float(\"Inf\")\n",
        "    answer_end_scores[:, ignore_index] = -float(\"Inf\")\n",
        "\n",
        "    # Выбор начального и конечного токенов для ответа\n",
        "    answer_start = torch.argmax(answer_start_scores)\n",
        "    answer_end = torch.argmax(answer_end_scores) + 1\n",
        "\n",
        "    # Извлечение токенов ответа\n",
        "    answer_tokens = tokenizer_docvqa.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "    answer_tokens = [token for token in answer_tokens if token not in (tokenizer_docvqa.cls_token, tokenizer_docvqa.sep_token, tokenizer_docvqa.pad_token)]\n",
        "\n",
        "    # Преобразование токенов в строку ответа\n",
        "    answer = tokenizer_docvqa.convert_tokens_to_string(answer_tokens)\n",
        "    answer_ru = translate(answer, \"en-ru\")\n",
        "\n",
        "    return answer_ru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "kQTZRCZCXY4L",
        "outputId": "368bbaab-b837-43a3-aeea-6d6815d59cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://8844cf670b9e9a1915.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8844cf670b9e9a1915.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://8844cf670b9e9a1915.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Определение интерфейса Gradio\n",
        "iface = gr.Interface(\n",
        "    fn=ru_inference,\n",
        "    inputs=[gr.Image(type=\"pil\"), gr.Textbox(lines=2, placeholder=\"Введите вопрос на русском языке\")],\n",
        "    outputs=gr.Textbox(),\n",
        ")\n",
        "\n",
        "# Запуск Gradio интерфейса\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJPiZ_u5UgpI"
      },
      "source": [
        "### [4 балла] Ответы на вопросы голосом\n",
        "\n",
        "Демо готово! Но кто хочет писать вопросы текстом?\n",
        "Здесь вам предстоить улучшить ваше демо, чтобы оно могло принимать вопросы голосом. За основу вам предлагается рассмотреть демо https://www.gradio.app/guides/real-time-speech-recognition и добавить соответствуещее окошко в ваше демо. Также вы можете добавить text-to-speech модель, чтобы оно озвучило текстовый ответ (дополнительный балл к оценке)\n",
        "\n",
        "---\n",
        "\n",
        "**Ожидаемый результат**\n",
        "\n",
        "В качестве результата в этой секции вам нужно код для запуска демо на градио и видеозапись его работы, где реализован описанный выше функционал."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-sSgkA3C3Ga",
        "outputId": "1a6fb666-4723-417c-922b-5ec789a5d712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gTTS\n",
            "  Downloading gTTS-2.4.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2023.7.22)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "qu-xHxq-CjGq"
      },
      "outputs": [],
      "source": [
        "# Импортируем необходимые библиотеки для TTS\n",
        "from gtts import gTTS\n",
        "import tempfile\n",
        "from io import BytesIO\n",
        "import io\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging"
      ],
      "metadata": {
        "id": "I4Oue05SgKdr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция преобразования текста в речь\n",
        "def text_to_speech(text, lang='ru'):\n",
        "    \"\"\"\n",
        "    Преобразование данного текста в аудио.\n",
        "\n",
        "    Параметры:\n",
        "    text (str): Текст для преобразования в речь.\n",
        "    lang (str): Языковой код для TTS.\n",
        "\n",
        "    Возвращает:\n",
        "    BytesIO: Буфер байтов аудиофайла.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        tts = gtts.gTTS(text=text, lang=lang)\n",
        "        # Создаем временный файл для сохранения аудио\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')\n",
        "        tts.save(temp_file.name)\n",
        "        return temp_file.name\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An unexpected error occurred in text_to_speech: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "VTaCDth6gTyr"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "EU-l4Wl2_ueV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0b44f31-1e17-4f26-f106-33d4e0a7585e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:This is a warning message\n",
            "ERROR:root:This is an error message\n"
          ]
        }
      ],
      "source": [
        "# Настройка логирования\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Использование логирования в функции recognize_speech\n",
        "def recognize_speech(audio_path):\n",
        "    r = sr.Recognizer()\n",
        "    try:\n",
        "        with sr.AudioFile(audio_path) as source:\n",
        "            audio = r.record(source)\n",
        "\n",
        "        logging.info(\"Аудиоданные успешно загружены\")\n",
        "        text = r.recognize_google(audio, language='ru-RU')\n",
        "        logging.info(\"Распознавание речи прошло успешно\")\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        logging.error(\"Сервис Google Speech Recognition не смог понять аудио\")\n",
        "    except sr.RequestError as e:\n",
        "        logging.error(f\"Не удалось отправить запрос в сервис Google Speech Recognition; {e}\")\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"Произошла непредвиденная ошибка в recognize_speech: {e}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "myfCYFQW_uhL"
      },
      "outputs": [],
      "source": [
        "# Функция обработки изображения и вопроса\n",
        "def ru_inference(image, audio=None):\n",
        "    try:\n",
        "        if audio is None:\n",
        "            logging.error(\"В функцию не был предоставлен аудио вход.\")\n",
        "            return None\n",
        "\n",
        "        # Распознавание речи из аудио\n",
        "        question_ru = recognize_speech(audio)\n",
        "        if question_ru is None:\n",
        "            raise ValueError(\"Не удалось распознать вопрос из аудио.\")\n",
        "\n",
        "        # Перевод вопроса на английский\n",
        "        question_en = translate(question_ru, \"ru-en\")\n",
        "\n",
        "        # Преобразование изображения в тензор PyTorch\n",
        "        transform = transforms.Compose([transforms.ToTensor()])\n",
        "        image_tensor = transform(image).unsqueeze(0)\n",
        "\n",
        "        # Препроцессинг изображения и вопроса и получение ответа моделью\n",
        "        inputs = processor_docvqa(image_tensor, question_en, return_tensors=\"pt\")\n",
        "        outputs = model_docvqa(**inputs)\n",
        "\n",
        "        # Игнорирование служебных токенов и извлечение ответа\n",
        "        ignore_tokens = [tokenizer_docvqa.cls_token_id, tokenizer_docvqa.sep_token_id, tokenizer_docvqa.pad_token_id]\n",
        "        answer_start_scores = outputs.start_logits\n",
        "        answer_end_scores = outputs.end_logits\n",
        "        answer_start_scores[:, ignore_tokens] = -float(\"Inf\")\n",
        "        answer_end_scores[:, ignore_tokens] = -float(\"Inf\")\n",
        "\n",
        "        answer_start = torch.argmax(answer_start_scores, dim=1)\n",
        "        answer_end = torch.argmax(answer_end_scores, dim=1) + 1\n",
        "\n",
        "        # Извлечение токенов ответа и преобразование их в строку\n",
        "        answer_tokens = tokenizer_docvqa.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "        answer_tokens = [token for token in answer_tokens if token not in (tokenizer_docvqa.cls_token, tokenizer_docvqa.sep_token, tokenizer_docvqa.pad_token)]\n",
        "        answer = tokenizer_docvqa.convert_tokens_to_string(answer_tokens)\n",
        "\n",
        "        # Перевод ответа на русский и преобразование в речь\n",
        "        answer_ru = translate(answer, \"en-ru\")\n",
        "        answer_audio_path = text_to_speech(answer_ru)\n",
        "\n",
        "        return answer_audio_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred in ru_inference: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.io.wavfile import write"
      ],
      "metadata": {
        "id": "AseeKh9ixGmN"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для записи и сохранения аудио\n",
        "def save_audio(audio_data, filename='audio.wav', sample_rate=44100):\n",
        "    if isinstance(audio_data, str):\n",
        "        with open(audio_data, 'rb') as f:\n",
        "            audio_data = f.read()\n",
        "    elif isinstance(audio_data, io.BytesIO):\n",
        "        audio_data = audio_data.read()\n",
        "\n",
        "    audio_data = np.frombuffer(audio_data, dtype=np.int16)\n",
        "    path = f'/content/sample_data{filename}'\n",
        "    write(path, sample_rate, audio_data)\n",
        "    return path"
      ],
      "metadata": {
        "id": "o0HpeH-xvJQl"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция-обёртка для Gradio, которая обрабатывает аудио и изображение\n",
        "def gradio_wrapper(image, audio_filepath):\n",
        "    if audio_filepath is None:\n",
        "        logging.error(\"No audio file path was provided.\")\n",
        "        return None\n",
        "    logging.info(f\"Audio file path received: {audio_filepath}\")\n",
        "\n",
        "    if not os.path.exists(audio_filepath):\n",
        "        logging.error(f\"Audio file does not exist at path: {audio_filepath}\")\n",
        "        return None\n",
        "\n",
        "    new_audio_path = save_audio(audio_filepath, filename='new_audio.wav')\n",
        "    logging.info(f\"Audio file was saved to a new location: {new_audio_path}\")\n",
        "\n",
        "    answer_audio_path = ru_inference(image, new_audio_path)\n",
        "    return answer_audio_path"
      ],
      "metadata": {
        "id": "Rrm0CbCryC6k"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "ISx8z6fI_uj_",
        "outputId": "90e2967f-fc48-4f75-e99b-d9f661155a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://548d01825218662c23.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://548d01825218662c23.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:No audio file path was provided.\n",
            "ERROR:root:Сервис Google Speech Recognition не смог понять аудио\n",
            "ERROR:root:An error occurred in ru_inference: Не удалось распознать вопрос из аудио.\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-83-b5614723b5db>\", line 11, in ru_inference\n",
            "    raise ValueError(\"Не удалось распознать вопрос из аудио.\")\n",
            "ValueError: Не удалось распознать вопрос из аудио.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://548d01825218662c23.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "# Создание интерфейса Gradio\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_wrapper,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\"),\n",
        "        gr.Audio(sources=\"microphone\", type=\"filepath\", label=\"Запишите ваш вопрос\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Audio(label=\"Озвученный ответ\")\n",
        "    ],\n",
        "    title=\"Интерфейс для вопросов и ответов\",\n",
        "    description=\"Загрузите изображение и введите или скажите свой вопрос.\"\n",
        ")\n",
        "\n",
        "# Запуск интерфейса Gradio\n",
        "iface.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc3af0e3c97648bdbf2f237e6f191b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44b852c4515e4ea9a42c2540822021cd",
              "IPY_MODEL_ce39a0bd8e6d44538dfd26ae1ab25e48",
              "IPY_MODEL_89da2388a2544e908a085e69cd70e61c",
              "IPY_MODEL_51aed6b46e52475eb5ceeb3c214532de",
              "IPY_MODEL_47e7793e71834836943058cc4bead54b"
            ],
            "layout": "IPY_MODEL_4e7fdbc7703f47f08607b42f9268a403"
          }
        },
        "44b852c4515e4ea9a42c2540822021cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75dc8f9face444dc92e5fcc677034be8",
            "placeholder": "​",
            "style": "IPY_MODEL_8d32c6719666484192023a37dba2804e",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ce39a0bd8e6d44538dfd26ae1ab25e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_20f930625be34b1f88faf13660fe1a6d",
            "placeholder": "​",
            "style": "IPY_MODEL_c77df7d72e5640e9a3dcec73d8ab2681",
            "value": ""
          }
        },
        "89da2388a2544e908a085e69cd70e61c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_dd4b7529027347978c18e6388bbacc14",
            "style": "IPY_MODEL_7baca6d3d8554f59b075b5e31438d3f9",
            "value": true
          }
        },
        "51aed6b46e52475eb5ceeb3c214532de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_970a8336d3ce46528dd505cd72e1a080",
            "style": "IPY_MODEL_7440e09fa22a438db819fb4918bb65a2",
            "tooltip": ""
          }
        },
        "47e7793e71834836943058cc4bead54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cd259cf7aba493facf9f52a40765cef",
            "placeholder": "​",
            "style": "IPY_MODEL_da7cbb4ee26d4306aeb3e967a7ebb521",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "4e7fdbc7703f47f08607b42f9268a403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "75dc8f9face444dc92e5fcc677034be8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d32c6719666484192023a37dba2804e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20f930625be34b1f88faf13660fe1a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c77df7d72e5640e9a3dcec73d8ab2681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd4b7529027347978c18e6388bbacc14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7baca6d3d8554f59b075b5e31438d3f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "970a8336d3ce46528dd505cd72e1a080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7440e09fa22a438db819fb4918bb65a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "4cd259cf7aba493facf9f52a40765cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da7cbb4ee26d4306aeb3e967a7ebb521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}