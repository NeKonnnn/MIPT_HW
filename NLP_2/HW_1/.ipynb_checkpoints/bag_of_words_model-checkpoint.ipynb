{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "004f2543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NeKonn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 2.7701 - accuracy: 0.0638 - val_loss: 2.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.7213 - accuracy: 0.0638 - val_loss: 2.7331 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.5984 - accuracy: 0.1702 - val_loss: 2.7658 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.5351 - accuracy: 0.1489 - val_loss: 2.8037 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.5459 - accuracy: 0.1489 - val_loss: 2.8065 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4785 - accuracy: 0.1915 - val_loss: 2.8157 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4285 - accuracy: 0.2128 - val_loss: 2.8025 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.3901 - accuracy: 0.1915 - val_loss: 2.8069 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.3417 - accuracy: 0.2766 - val_loss: 2.7953 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1985 - accuracy: 0.3191 - val_loss: 2.8017 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.1052 - accuracy: 0.3830 - val_loss: 2.8280 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.0408 - accuracy: 0.3830 - val_loss: 2.7934 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.7813 - accuracy: 0.5106 - val_loss: 2.8309 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8371 - accuracy: 0.5106 - val_loss: 2.8637 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8780 - accuracy: 0.5319 - val_loss: 2.8228 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.6289 - accuracy: 0.5319 - val_loss: 2.8415 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5269 - accuracy: 0.6383 - val_loss: 2.8699 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.4170 - accuracy: 0.6383 - val_loss: 2.7921 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.5134 - accuracy: 0.6170 - val_loss: 2.6675 - val_accuracy: 0.1667\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1747 - accuracy: 0.7021 - val_loss: 2.6510 - val_accuracy: 0.1667\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.4354 - accuracy: 0.5532 - val_loss: 2.7163 - val_accuracy: 0.1667\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0795 - accuracy: 0.7660 - val_loss: 2.7733 - val_accuracy: 0.1667\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0902 - accuracy: 0.7234 - val_loss: 2.6576 - val_accuracy: 0.1667\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0881 - accuracy: 0.7234 - val_loss: 2.5696 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1052 - accuracy: 0.6809 - val_loss: 2.5957 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8832 - accuracy: 0.7234 - val_loss: 2.5873 - val_accuracy: 0.1667\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8208 - accuracy: 0.8298 - val_loss: 2.5922 - val_accuracy: 0.3333\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7849 - accuracy: 0.8298 - val_loss: 2.6503 - val_accuracy: 0.3333\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8051 - accuracy: 0.7660 - val_loss: 2.6704 - val_accuracy: 0.3333\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.8298 - val_loss: 2.7308 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7508 - accuracy: 0.7660 - val_loss: 2.8021 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.8936 - val_loss: 2.8292 - val_accuracy: 0.3333\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.8085 - val_loss: 2.8045 - val_accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.8936 - val_loss: 2.8995 - val_accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7876 - accuracy: 0.7447 - val_loss: 2.9877 - val_accuracy: 0.1667\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.8723 - val_loss: 2.9005 - val_accuracy: 0.3333\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.8723 - val_loss: 2.8345 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.8723 - val_loss: 2.7685 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.8723 - val_loss: 2.7680 - val_accuracy: 0.3333\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8936 - val_loss: 2.8391 - val_accuracy: 0.3333\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.9362 - val_loss: 2.8294 - val_accuracy: 0.3333\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8936 - val_loss: 2.9035 - val_accuracy: 0.3333\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.9362 - val_loss: 3.0336 - val_accuracy: 0.1667\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.9574 - val_loss: 3.0769 - val_accuracy: 0.3333\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.8085 - val_loss: 3.0303 - val_accuracy: 0.1667\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.9149 - val_loss: 3.0734 - val_accuracy: 0.3333\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.9362 - val_loss: 2.9974 - val_accuracy: 0.3333\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.9362 - val_loss: 2.7955 - val_accuracy: 0.3333\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.9362 - val_loss: 2.7781 - val_accuracy: 0.3333\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8936 - val_loss: 2.7694 - val_accuracy: 0.3333\n",
      "Model created and trained successfully\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 128)               17024     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 15)                975       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26255 (102.56 KB)\n",
      "Trainable params: 26255 (102.56 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Загрузка и чтение датасета\n",
    "with open(\"data/data_IN/chatbot_data.json\", encoding='utf-8') as file:\n",
    "    intents = json.load(file)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!']\n",
    "\n",
    "# Предобработка данных\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        documents.append((w, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "# Сохранение слов и классов\n",
    "pickle.dump(words, open('words.pkl', 'wb'))\n",
    "pickle.dump(classes, open('classes.pkl', 'wb'))\n",
    "\n",
    "# Создание обучающего набора данных\n",
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "for doc in documents:\n",
    "    bag = []\n",
    "    pattern_words = doc[0]\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    for w in words:\n",
    "        bag.append(1 if w in pattern_words else 0)\n",
    "    \n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "# Преобразование training в отдельные массивы NumPy для train_x и train_y\n",
    "random.shuffle(training)\n",
    "train_x = np.array([np.array(x[0]) for x in training])\n",
    "train_y = np.array([np.array(x[1]) for x in training])\n",
    "\n",
    "# Разделение данных на обучающий и валидационный наборы\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.1)\n",
    "\n",
    "# Инициализация расписания скорости обучения\n",
    "initial_learning_rate = 0.01\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "# Построение модели\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "# Инициализация и компиляция модели с новым оптимизатором\n",
    "sgd = SGD(learning_rate=lr_schedule, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# Загрузка или обучение модели\n",
    "history = None  # Инициализация переменной для истории обучения\n",
    "try:\n",
    "    model = load_model('chatbot_model.h5')\n",
    "    print(\"Model loaded successfully\")\n",
    "except:\n",
    "    history = model.fit(train_x, train_y, epochs=50, batch_size=5, verbose=1, validation_data=(val_x, val_y))\n",
    "    model.save('chatbot_model.h5')\n",
    "    print(\"Model created and trained successfully\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Визуализация потерь для обучающего и валидационного наборов\n",
    "if history is not None:\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ca9a2",
   "metadata": {},
   "source": [
    "Исходя из результатов обучения модели, видно, что точность на обучающем наборе данных постепенно увеличивается. Однако точность на валидационном наборе данных остается низкой и не демонстрирует значительного улучшения, что может указывать на переобучение модели или недостаточное обобщение. \n",
    "\n",
    "Предполагаю, что валидационный набор данных слишком мал или не представляет всего разнообразия данных, на которых модель должна хорошо работать. Думается, что необходимо изначально подавать больше данных, что не представляется возможным в виду ограниченности времени!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56ec5848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000015C2E522CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "О, Морти, ты это ты! Чего надо?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NeKonn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def clean_up_sentence(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "def bag_of_words(sentence, words):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0] * len(words)\n",
    "    for s in sentence_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == s:\n",
    "                bag[i] = 1\n",
    "    return np.array(bag)\n",
    "\n",
    "def predict_class(sentence, model, words, classes):\n",
    "    bow = bag_of_words(sentence, words)\n",
    "    res = model.predict(np.array([bow]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list\n",
    "\n",
    "def get_response(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if i['tag'] == tag:\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "\n",
    "# Загрузка обученных данных и модели\n",
    "words = pickle.load(open('words.pkl', 'rb'))\n",
    "classes = pickle.load(open('classes.pkl', 'rb'))\n",
    "model = load_model('chatbot_model.h5')\n",
    "intents = json.loads(open('data/data_IN/chatbot_data.json', encoding='utf-8').read())\n",
    "\n",
    "# Функция для получения ответа\n",
    "def chatbot_response(text):\n",
    "    ints = predict_class(text, model, words, classes)\n",
    "    res = get_response(ints, intents)\n",
    "    return res\n",
    "\n",
    "# Пример запроса\n",
    "question = \"Привет, как дела?\"\n",
    "response = chatbot_response(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f6b256d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Сегодня я покажу тебе что-то, что заставит тебя пересмотреть все твои взгляды на жизнь, Морти.\n"
     ]
    }
   ],
   "source": [
    "# Пример запроса\n",
    "question = \"Чем займемся сегодня?\"\n",
    "response = chatbot_response(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059793c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef3820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e0f8a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\NeKonn\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.127772569656372\n",
      "Epoch: 1, Loss: 0.07860892917960882\n",
      "Epoch: 2, Loss: 0.05245049484074116\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "\n",
    "# Загрузка данных из JSON\n",
    "with open('data/data_IN/chatbot_data.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Преобразование данных в DataFrame\n",
    "patterns, responses = [], []\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        patterns.append(pattern)\n",
    "        responses.append(intent['responses'][0])  # Берем первый ответ для упрощения\n",
    "\n",
    "df = pd.DataFrame({'pattern': patterns, 'response': responses})\n",
    "\n",
    "# Токенизация данных\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pattern = str(self.data.pattern[index])\n",
    "        response = str(self.data.response[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            pattern,\n",
    "            response,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(1, dtype=torch.long)  # Предполагаем, что все пары вопрос-ответ положительные\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Параметры\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "EPOCHS = 3\n",
    "\n",
    "# Создание экземпляра Dataset и DataLoader\n",
    "dataset = ChatbotDataset(df, tokenizer, MAX_LEN)\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Инициализация модели и оптимизатора\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Цикл обучения\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for _, data in enumerate(train_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype=torch.long)\n",
    "        mask = data['mask'].to(device, dtype=torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "        outputs = model(ids, token_type_ids=token_type_ids, attention_mask=mask, labels=targets)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch: {epoch}, Loss: {total_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a7dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e33286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8ea722",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Ragnar6.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Загрузка данных\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRagnar6.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Проверка загруженных данных\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Ragnar6.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('Ragnar6.csv', delimiter=';')\n",
    "\n",
    "# Проверка загруженных данных\n",
    "print(df.head())\n",
    "# Токенизация данных\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "class RagnarDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        context = str(self.data.context[index])\n",
    "        answer = str(self.data.answer[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            context,\n",
    "            answer,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(1, dtype=torch.long)  # Предполагается, что все пары контекст-ответ положительные\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    # Параметры\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "EPOCHS = 3\n",
    "# Создание экземпляра Dataset и DataLoader\n",
    "dataset = RagnarDataset(df, tokenizer, MAX_LEN)\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for _,data in enumerate(train_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, token_type_ids=token_type_ids, attention_mask=mask, labels=targets)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch: {epoch}, Loss:  {total_loss/len(train_loader)}')\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка модели и токенизатора\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()  # Перевод модели в режим оценки\n",
    "\n",
    "# Функция для создания эмбеддинга\n",
    "def create_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[:,0,:].detach().numpy().flatten()  # Используем flatten\n",
    "    return embeddings\n",
    "\n",
    "# Загрузка датасета\n",
    "df = pd.read_csv('Ragnar6.csv', delimiter=';')\n",
    "\n",
    "# Убедимся, что все ответы являются строками\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "\n",
    "# Создание эмбеддингов для реплик Рагнара\n",
    "answer_embeddings = {}\n",
    "for index, row in df.iterrows():\n",
    "    answer = row['answer']  # Используем столбец 'answer' для реплик Рагнара\n",
    "    answer_embeddings[answer] = create_embedding(answer, tokenizer, model)\n",
    "\n",
    "#Загрузка модели и токенизатора\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()  # Перевод модели в режим оценки\n",
    "\n",
    "# Функция для создания эмбеддинга\n",
    "def create_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[:,0,:].detach().numpy().flatten()  # Используем flatten\n",
    "    return embeddings\n",
    "\n",
    "# Загрузка датасета\n",
    "df = pd.read_csv('Ragnar6.csv', delimiter=';')\n",
    "\n",
    "# Убедимся, что все ответы являются строками\n",
    "df['answer'] = df['answer'].astype(str)\n",
    "\n",
    "# Создание эмбеддингов для реплик Рагнара\n",
    "answer_embeddings = {}\n",
    "for index, row in df.iterrows():\n",
    "    answer = row['answer']  # Используем столбец 'answer' для реплик Рагнара\n",
    "    answer_embeddings[answer] = create_embedding(answer, tokenizer, model)\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "def find_best_match(question, answer_embeddings, tokenizer, model):\n",
    "    question_embedding = create_embedding(question, tokenizer, model)\n",
    "    min_distance = float('inf')\n",
    "    best_match = None\n",
    "    for answer, embedding in answer_embeddings.items():\n",
    "        distance = cosine(question_embedding, embedding)  # Убран вызов squeeze\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            best_match = answer\n",
    "    return best_match\n",
    "\n",
    "# Пример использования\n",
    "question = \"Что ты думаешь о богах?\"\n",
    "best_match_replica = find_best_match(question, answer_embeddings, tokenizer, model)\n",
    "print(f\"Ответ Рагнара: {best_match_replica}\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка датасета\n",
    "df = pd.read_csv('Ragnar6.csv', delimiter=';')\n",
    "\n",
    "df['label'] = 1  # Все пары контекст-ответ релевантны\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "train_df, val_df = train_test_split(df, test_size=0.1)  # Здесь мы используем 10% данных для валидации\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class RagnarDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        context = str(self.data.iloc[index]['context'])\n",
    "        answer = str(self.data.iloc[index]['answer'])\n",
    "        label = self.data.iloc[index]['label']\n",
    "        # Объединение контекста и ответа в одну строку\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            context,\n",
    "            answer,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)  # Две метки: релевантный и нерелевантный\n",
    "\n",
    "# Параметры\n",
    "max_length = 512\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = RagnarDataset(train_df, tokenizer, max_length)\n",
    "val_dataset = RagnarDataset(val_df, tokenizer, max_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(3):  # Пример с тремя эпохами\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # После каждой эпохи выводим среднюю потерю\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}, Loss: {avg_train_loss}')\n",
    "\n",
    "    # Валидация (простой пример)\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(val_loader)\n",
    "    print(f'Validation Loss: {avg_val_loss}')\n",
    "\n",
    "def predict(context, answer, tokenizer, model, device):\n",
    "    model.eval()\n",
    "    inputs = tokenizer.encode_plus(context, answer, return_tensors=\"pt\", max_length=512, padding=True, truncation=True)\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "        prediction = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "    return prediction.cpu().numpy(), probabilities.cpu().numpy()\n",
    "\n",
    "# Пример использования\n",
    "context = \"Ваш вопрос или контекст\"\n",
    "answer = \"Потенциальный ответ Рагнара\"\n",
    "prediction, probabilities = predict(context, answer, tokenizer, model, device)\n",
    "print(f\"Класс: {prediction}, Вероятности: {probabilities}\")\n",
    "\n",
    "# Заменяем NaN на пустые строки в столбцах 'context' и 'answer'\n",
    "df['context'] = df['context'].fillna('')\n",
    "df['answer'] = df['answer'].fillna('')\n",
    "\n",
    "def predict(context, answer, tokenizer, model, device):\n",
    "    # Убедимся, что контекст и ответ являются строками\n",
    "    context = str(context)\n",
    "    answer = str(answer)\n",
    "\n",
    "    model.eval()\n",
    "    inputs = tokenizer.encode_plus(context, answer, return_tensors=\"pt\", max_length=512, padding=True, truncation=True)\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "        prediction = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "    return prediction.cpu().numpy(), probabilities.cpu().numpy()\n",
    "\n",
    "context = \"Как дела?\"  # вопрос к Рагнару\n",
    "\n",
    "best_score = 0\n",
    "best_answer = None\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    answer = row['answer']  # Используем реплику Рагнара как потенциальный ответ\n",
    "    prediction, probabilities = predict(context, answer, tokenizer, model, device)\n",
    "\n",
    "    # Проверяем вероятность релевантности (класс 1)\n",
    "    score = probabilities[0][1]\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_answer = answer\n",
    "\n",
    "print(f\"Лучший ответ Рагнара: {best_answer} с вероятностью релевантности {best_score}\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Предполагается, что модель, train_loader и val_loader уже инициализированы\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3  # Или любое другое количество эпох\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}')\n",
    "\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feedc1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
