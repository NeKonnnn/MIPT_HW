{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3bc8e3c",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download ru_core_news_lg > null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3130e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "import collections\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "import optuna\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b94e87",
   "metadata": {},
   "source": [
    "# Загрузка данных и установка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a58ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета\n",
    "dataset = load_dataset(\"sberquad\")\n",
    "\n",
    "# Извлечение контекста и вопроса из тренировочного набора данных\n",
    "train_context = dataset[\"train\"][0][\"context\"]\n",
    "train_question = dataset[\"train\"][0][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb7caff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'В протерозойских отложениях органические остатки встречаются намного чаще, чем в архейских. Они представлены известковыми выделениями сине-зелёных водорослей, ходами червей, остатками кишечнополостных. Кроме известковых водорослей, к числу древнейших растительных остатков относятся скопления графито-углистого вещества, образовавшегося в результате разложения Corycium enigmaticum. В кремнистых сланцах железорудной формации Канады найдены нитевидные водоросли, грибные нити и формы, близкие современным кокколитофоридам. В железистых кварцитах Северной Америки и Сибири обнаружены железистые продукты жизнедеятельности бактерий.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2712cca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Определение устройства для выполнения: CUDA (GPU) или CPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd03116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к предварительно обученной модели RuBERT\n",
    "bert_checkpoint = 'DeepPavlov/rubert-base-cased'\n",
    "\n",
    "# Инициализация токенизатора для RuBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2459c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизация вопроса и контекста\n",
    "tokenized_inputs = tokenizer(train_question, train_context)\n",
    "\n",
    "# Декодирование токенизированных входных данных обратно в текст для проверки\n",
    "tokenizer.decode(tokenized_inputs[\"input_ids\"])\n",
    "\n",
    "# Установка максимальной длины входного текста и шага для разбиения на части (stride)\n",
    "max_input_length = 384\n",
    "input_stride = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704038ec",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bf496a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для предобработки тренировочных данных\n",
    "def preprocess_train_data(examples):\n",
    "    # Убираем пробельные символы из вопросов\n",
    "    question_list = [q.strip() for q in examples['question']]\n",
    "    \n",
    "    # Токенизация вопросов и контекстов\n",
    "    tokenized_data = tokenizer(\n",
    "        question_list,\n",
    "        examples['context'],\n",
    "        max_length=max_input_length,\n",
    "        truncation='only_second',\n",
    "        stride=input_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding='max_length',\n",
    "    )\n",
    "    \n",
    "    # Извлекаем данные смещения и данные сэмплирования\n",
    "    offset_mapping_data = tokenized_data.pop('offset_mapping')\n",
    "    sample_mapping_data = tokenized_data.pop('overflow_to_sample_mapping')\n",
    "    \n",
    "    # Извлекаем данные ответов\n",
    "    answer_data = examples['answers']\n",
    "    start_positions_data = []\n",
    "    end_positions_data = []\n",
    "\n",
    "    # Определение позиций начала и конца ответа в токенизированных данных\n",
    "    for (i, offset) in enumerate(offset_mapping_data):\n",
    "        sample_idx = sample_mapping_data[i]\n",
    "        answer_info = answer_data[sample_idx]\n",
    "        start_char_idx = answer_info['answer_start'][0]\n",
    "        end_char_idx = answer_info['answer_start'][0] + len(answer_info['text'][0])\n",
    "        sequence_ids_data = tokenized_data.sequence_ids(i)\n",
    "\n",
    "        # Находим начало и конец контекста в токенизированных данных\n",
    "        idx = 0\n",
    "        while sequence_ids_data[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start_idx = idx\n",
    "        while sequence_ids_data[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end_idx = idx - 1\n",
    "\n",
    "        # Определяем позиции начала и конца ответа\n",
    "        if offset[context_start_idx][0] > start_char_idx \\\n",
    "            or offset[context_end_idx][1] < end_char_idx:\n",
    "            start_positions_data.append(0)\n",
    "            end_positions_data.append(0)\n",
    "        else:\n",
    "            idx = context_start_idx\n",
    "            while idx <= context_end_idx and offset[idx][0] <= start_char_idx:\n",
    "                idx += 1\n",
    "            start_positions_data.append(idx - 1)\n",
    "\n",
    "            idx = context_end_idx\n",
    "            while idx >= context_start_idx and offset[idx][1] >= end_char_idx:\n",
    "                idx -= 1\n",
    "            end_positions_data.append(idx + 1)\n",
    "\n",
    "    # Добавляем позиции начала и конца ответа в токенизированные данные\n",
    "    tokenized_data['start_positions'] = start_positions_data\n",
    "    tokenized_data['end_positions'] = end_positions_data\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d390ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для предобработки валидационных данных\n",
    "def preprocess_val_data(examples):\n",
    "    # Убираем пробельные символы из вопросов\n",
    "    question_list = [q.strip() for q in examples['question']]\n",
    "    \n",
    "    # Токенизация вопросов и контекстов\n",
    "    tokenized_data = tokenizer(\n",
    "        question_list,\n",
    "        examples['context'],\n",
    "        max_length=max_input_length,\n",
    "        truncation='only_second',\n",
    "        stride=input_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding='max_length',\n",
    "    )\n",
    "\n",
    "    # Извлекаем данные сэмплирования\n",
    "    sample_mapping_data = tokenized_data.pop('overflow_to_sample_mapping')\n",
    "    example_id_data = []\n",
    "\n",
    "    # Присваиваем каждому токенизированному элементу его идентификатор из исходных данных\n",
    "    for i in range(len(tokenized_data['input_ids'])):\n",
    "        sample_idx = sample_mapping_data[i]\n",
    "        example_id_data.append(examples['id'][sample_idx])\n",
    "\n",
    "        # Корректировка данных смещения для учета только контекста (без вопроса)\n",
    "        sequence_ids_data = tokenized_data.sequence_ids(i)\n",
    "        offset_data = tokenized_data['offset_mapping'][i]\n",
    "        tokenized_data['offset_mapping'][i] = [(o if sequence_ids_data[k] == 1 else None) for (k, o) in enumerate(offset_data)]\n",
    "\n",
    "    tokenized_data['example_id'] = example_id_data\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c7fe83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c35be19a37c4aab825f249d56251050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5036 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Применяем функции предобработки к наборам данных\n",
    "processed_train_dataset = dataset[\"train\"].map(\n",
    "    preprocess_train_data,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "processed_val_dataset = dataset[\"validation\"].map(\n",
    "    preprocess_val_data,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"validation\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "912ae4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочного набора до обработки: 45328, после: 45544\n",
      "Размер валидационного набора до обработки: 5036, после: 5063\n"
     ]
    }
   ],
   "source": [
    "# Выводим размеры наборов данных до и после предобработки\n",
    "print(f'Размер тренировочного набора до обработки: {len(dataset[\"train\"])}, после: {len(processed_train_dataset)}')\n",
    "print(f'Размер валидационного набора до обработки: {len(dataset[\"validation\"])}, после: {len(processed_val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7b381",
   "metadata": {},
   "source": [
    "# Построение и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6bd7482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели для ответа на вопросы из предварительно обученного чекпоинта\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(bert_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fffe0f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка параметров обучения\n",
    "training_args = TrainingArguments(\n",
    "    \"DeepPavlov/rubert-base-cased\",    # путь для сохранения обученной модели\n",
    "    evaluation_strategy=\"no\",          # стратегия оценки во время обучения (в данном случае - нет оценки)\n",
    "    save_strategy=\"epoch\",             # сохранять модель после каждой эпохи\n",
    "    learning_rate=2e-5,                # скорость обучения\n",
    "    num_train_epochs=3,                # количество эпох обучения\n",
    "    weight_decay=0.01,                 # коэффициент уменьшения весов (L2 регуляризация)\n",
    "    fp16=True,                         # использование 16-битной точности (уменьшает использование памяти и ускоряет обучение)\n",
    ")\n",
    "\n",
    "# Инициализация тренера для обучения модели\n",
    "trainer_instance = Trainer(\n",
    "    model=qa_model,                                 # модель для обучения\n",
    "    args=training_args,                             # параметры обучения\n",
    "    train_dataset=processed_train_dataset,          # тренировочный набор данных\n",
    "    eval_dataset=processed_val_dataset,             # валидационный набор данных\n",
    "    tokenizer=tokenizer,                            # токенизатор для преобразования текста в токены\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a9d616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17079' max='17079' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17079/17079 38:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.734100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.978200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.861500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.771400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.710800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.659600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.644400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.604100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.600100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.598000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.574700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.375800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.261700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.304200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.269200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.225700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.229500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.262600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.277200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.209000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.201900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.134200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.933300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.944400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.924900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.895900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.905600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.912600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.872800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.894800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.883000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Запуск процесса обучения\n",
    "trainer_instance.train()\n",
    "\n",
    "# Получение предсказаний модели на валидационном наборе данных\n",
    "predictions, _, _ = trainer_instance.predict(processed_val_dataset)\n",
    "\n",
    "# Разделение предсказаний на начальные и конечные логиты (вероятности начала и конца ответа)\n",
    "start_logits, end_logits = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d309fc",
   "metadata": {},
   "source": [
    "# Оценка качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddf6992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка метрики для оценки качества модели на задаче SQuAD\n",
    "evaluation_metric = evaluate.load(\"squad\")\n",
    "\n",
    "# Установка параметров для вычисления метрик\n",
    "n_best = 20\n",
    "max_answer_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ab71a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3008d87f6d19487d904fbd7dc1ed7e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 57.744241461477365, 'f1': 78.08301491321691}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Функция для вычисления метрик качества модели\n",
    "def evaluate_model(start_logits_data, end_logits_data, features_data, examples_data):\n",
    "    # Словарь для хранения связи между примерами и их признаками\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features_data):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples_data):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Обработка всех признаков, связанных с данным примером\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits_data[feature_index]\n",
    "            end_logit = end_logits_data[feature_index]\n",
    "            offsets = features_data[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            # Выбор лучших индексов начала и конца ответа\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Пропускаем ответы, которые не полностью находятся в контексте\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Пропускаем ответы слишком короткой или длинной длины\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    # Формирование ответа\n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Выбор наилучшего ответа\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": str(example_id), \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": str(example_id), \"prediction_text\": \"\"})\n",
    "\n",
    "    # Сравнение предсказанных ответов с эталонными\n",
    "    theoretical_answers = [{\"id\": str(ex[\"id\"]), \"answers\": ex[\"answers\"]} for ex in examples_data]\n",
    "    return evaluation_metric.compute(predictions=predicted_answers, references=theoretical_answers)\n",
    "\n",
    "# Применение функции оценки качества к предсказаниям модели\n",
    "evaluate_model(start_logits, end_logits, processed_val_dataset, dataset[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df1615e",
   "metadata": {},
   "source": [
    "# Выводы:\n",
    "\n",
    "Наша модель показывает хорошие результаты в задаче вопросно-ответных систем на этом наборе данных.\n",
    "Она правильно ответила примерно на 58% вопросов и была близка к правильному ответу еще в ряде случаев, что подтверждается F1-оценкой в 78%.\n",
    "\n",
    "Общие выводы:\n",
    "\n",
    "- В коде явно не указано использование lr scheduler. Однако стоит отметить, что TrainingArguments в библиотеке transformers по умолчанию использует lr scheduler.\n",
    "- В коде используется модель DeepPavlov/rubert-base-cased из библиотеки transformers, которая представляет собой одну из современных архитектур для QA. Это одна из вариаций BERT, предназначенная для создания многоязычных эмбеддингов предложений.\n",
    "- В TrainingArguments указан параметр weight_decay, который является коэффициентом L2-регуляризации. Это помогает предотвратить переобучение модели.\n",
    "- Используется стандартная функция потерь для задачи классификации токенов в AutoModelForTokenClassification. Эта функция потерь обычно основана на кросс-энтропии."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
